{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "combined_data= pd.read_csv('combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.3688 - loss: 0.8667 - val_accuracy: 0.6667 - val_loss: 0.8589 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4272 - loss: 0.8611 - val_accuracy: 0.6667 - val_loss: 0.8549 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5977 - loss: 0.8576 - val_accuracy: 0.6667 - val_loss: 0.8508 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6556 - loss: 0.8507 - val_accuracy: 0.6667 - val_loss: 0.8467 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5876 - loss: 0.8473 - val_accuracy: 0.6667 - val_loss: 0.8424 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6969 - loss: 0.8412 - val_accuracy: 0.6667 - val_loss: 0.8385 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6656 - loss: 0.8396 - val_accuracy: 0.6667 - val_loss: 0.8348 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6865 - loss: 0.8322 - val_accuracy: 0.6667 - val_loss: 0.8308 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6569 - loss: 0.8301 - val_accuracy: 0.6667 - val_loss: 0.8265 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7107 - loss: 0.8194 - val_accuracy: 0.6667 - val_loss: 0.8216 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6397 - loss: 0.8213 - val_accuracy: 0.6667 - val_loss: 0.8167 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6772 - loss: 0.8090 - val_accuracy: 0.6667 - val_loss: 0.8111 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6854 - loss: 0.8055 - val_accuracy: 0.6667 - val_loss: 0.8053 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6522 - loss: 0.8024 - val_accuracy: 0.6667 - val_loss: 0.7993 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7340 - loss: 0.7861 - val_accuracy: 0.6667 - val_loss: 0.7934 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6557 - loss: 0.7870 - val_accuracy: 0.6667 - val_loss: 0.7877 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6839 - loss: 0.7805 - val_accuracy: 0.6667 - val_loss: 0.7812 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6854 - loss: 0.7747 - val_accuracy: 0.6667 - val_loss: 0.7742 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6739 - loss: 0.7687 - val_accuracy: 0.6667 - val_loss: 0.7667 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6969 - loss: 0.7393 - val_accuracy: 0.6667 - val_loss: 0.7582 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7048 - loss: 0.7260 - val_accuracy: 0.6667 - val_loss: 0.7501 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6742 - loss: 0.7325 - val_accuracy: 0.6667 - val_loss: 0.7409 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6928 - loss: 0.7032 - val_accuracy: 0.6667 - val_loss: 0.7330 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7312 - loss: 0.6746 - val_accuracy: 0.6667 - val_loss: 0.7240 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7064 - loss: 0.6853 - val_accuracy: 0.6667 - val_loss: 0.7154 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6608 - loss: 0.6490 - val_accuracy: 0.6111 - val_loss: 0.7089 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6806 - loss: 0.6423 - val_accuracy: 0.5833 - val_loss: 0.7010 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7669 - loss: 0.6163 - val_accuracy: 0.5833 - val_loss: 0.6943 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8186 - loss: 0.5935 - val_accuracy: 0.5833 - val_loss: 0.6894 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6923 - loss: 0.6159 - val_accuracy: 0.5833 - val_loss: 0.6819 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8069 - loss: 0.5664 - val_accuracy: 0.5833 - val_loss: 0.6747 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8239 - loss: 0.5292 - val_accuracy: 0.5833 - val_loss: 0.6680 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8292 - loss: 0.5214 - val_accuracy: 0.6389 - val_loss: 0.6619 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8247 - loss: 0.5436 - val_accuracy: 0.6944 - val_loss: 0.6550 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8284 - loss: 0.5171 - val_accuracy: 0.7222 - val_loss: 0.6508 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8235 - loss: 0.5094 - val_accuracy: 0.7222 - val_loss: 0.6512 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8748 - loss: 0.4574 - val_accuracy: 0.7222 - val_loss: 0.6520 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7838 - loss: 0.4920 - val_accuracy: 0.6944 - val_loss: 0.6534 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8834 - loss: 0.4296 - val_accuracy: 0.6944 - val_loss: 0.6519 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8737 - loss: 0.4306 - val_accuracy: 0.6944 - val_loss: 0.6461 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9037 - loss: 0.3748 - val_accuracy: 0.7500 - val_loss: 0.6446 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9338 - loss: 0.3668 - val_accuracy: 0.7500 - val_loss: 0.6422 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9495 - loss: 0.3569 - val_accuracy: 0.7222 - val_loss: 0.6468 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9071 - loss: 0.3926 - val_accuracy: 0.7222 - val_loss: 0.6510 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9550 - loss: 0.3536 - val_accuracy: 0.7222 - val_loss: 0.6480 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9171 - loss: 0.3434 - val_accuracy: 0.7222 - val_loss: 0.6421 - learning_rate: 3.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.3347 - val_accuracy: 0.6944 - val_loss: 0.6361 - learning_rate: 3.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9339 - loss: 0.3814 - val_accuracy: 0.6944 - val_loss: 0.6271 - learning_rate: 3.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9163 - loss: 0.3404 - val_accuracy: 0.7500 - val_loss: 0.6162 - learning_rate: 3.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9513 - loss: 0.2997 - val_accuracy: 0.7500 - val_loss: 0.6011 - learning_rate: 3.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9139 - loss: 0.3356 - val_accuracy: 0.7500 - val_loss: 0.5895 - learning_rate: 3.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9391 - loss: 0.3102 - val_accuracy: 0.7500 - val_loss: 0.5823 - learning_rate: 3.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.2776 - val_accuracy: 0.7500 - val_loss: 0.5765 - learning_rate: 3.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9528 - loss: 0.2794 - val_accuracy: 0.8056 - val_loss: 0.5671 - learning_rate: 3.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.2744 - val_accuracy: 0.8056 - val_loss: 0.5706 - learning_rate: 3.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.2467 - val_accuracy: 0.8056 - val_loss: 0.5655 - learning_rate: 3.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9747 - loss: 0.2689 - val_accuracy: 0.8333 - val_loss: 0.5568 - learning_rate: 3.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9703 - loss: 0.2753 - val_accuracy: 0.8056 - val_loss: 0.5719 - learning_rate: 3.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9718 - loss: 0.2175 - val_accuracy: 0.8056 - val_loss: 0.5762 - learning_rate: 3.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9658 - loss: 0.2391 - val_accuracy: 0.8056 - val_loss: 0.5726 - learning_rate: 3.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9948 - loss: 0.2110 - val_accuracy: 0.8611 - val_loss: 0.5788 - learning_rate: 3.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9688 - loss: 0.2040 - val_accuracy: 0.8333 - val_loss: 0.5856 - learning_rate: 3.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9926 - loss: 0.1926 - val_accuracy: 0.8333 - val_loss: 0.5875 - learning_rate: 1.5000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9453 - loss: 0.2583 - val_accuracy: 0.8333 - val_loss: 0.5884 - learning_rate: 1.5000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.2127 - val_accuracy: 0.8333 - val_loss: 0.5873 - learning_rate: 1.5000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9862 - loss: 0.1968 - val_accuracy: 0.8611 - val_loss: 0.5854 - learning_rate: 1.5000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1725 - val_accuracy: 0.8611 - val_loss: 0.5832 - learning_rate: 1.5000e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step\n",
      "Improved Binary Classification Accuracy: 0.8333333333333334\n",
      "Improved Binary Classification F1 Score: 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "X = combined_data.drop(columns=['Segment', 'Subject NO.', 'Gender'])\n",
    "y_binary = combined_data['Segment'].apply(lambda x: 0 if x == 'EO' else 1)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for LSTM input [samples, timesteps, features]\n",
    "X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Build an improved Hybrid LSTM + NN Model\n",
    "model = Sequential()\n",
    "\n",
    "# Bidirectional LSTM Layer with max_norm constraint to prevent exploding gradients\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_constraint=max_norm(3)), input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "model.add(Dropout(0.5))  # Increased Dropout rate to reduce overfitting\n",
    "\n",
    "# Second LSTM Layer for added depth\n",
    "model.add(LSTM(64, return_sequences=False, kernel_constraint=max_norm(3)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Fully Connected (Dense) Layers with L2 regularization and Dropout\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output Layer (sigmoid for binary classification)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the Model with Adam optimizer and a smaller learning rate\n",
    "optimizer = Adam(learning_rate=0.0003, clipvalue=1.0)  # Gradient clipping added\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model for more epochs with smaller batch size and callbacks\n",
    "model.fit(X_train_lstm, y_train, epochs=150, batch_size=16, verbose=1, validation_data=(X_test_lstm, y_test), \n",
    "          callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "binary_predictions = model.predict(X_test_lstm)\n",
    "binary_predictions = (binary_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "binary_acc = accuracy_score(y_test, binary_predictions)\n",
    "binary_f1 = f1_score(y_test, binary_predictions)\n",
    "\n",
    "print(f\"Improved Binary Classification Accuracy: {binary_acc}\")\n",
    "print(f\"Improved Binary Classification F1 Score: {binary_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject NO.</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Mean HR (BPM)</th>\n",
       "      <th>AVNN (ms)</th>\n",
       "      <th>SDNN (ms)</th>\n",
       "      <th>NN50 (beats)</th>\n",
       "      <th>pNN50 (%)</th>\n",
       "      <th>RMSSD (ms)</th>\n",
       "      <th>LF (ms2)</th>\n",
       "      <th>LF Norm (n.u.)</th>\n",
       "      <th>...</th>\n",
       "      <th>Alpha_(P 3 - P 4)</th>\n",
       "      <th>Beta1_(Fp 1 - Fp 2)</th>\n",
       "      <th>Beta1_(F 3 - F 4)</th>\n",
       "      <th>Beta1_(T 3 - T 4)</th>\n",
       "      <th>Beta1_(P 3 - P 4)</th>\n",
       "      <th>Beta2_(Fp 1 - Fp 2)</th>\n",
       "      <th>Beta2_(F 3 - F 4)</th>\n",
       "      <th>Beta2_(T 3 - T 4)</th>\n",
       "      <th>Beta2_(P 3 - P 4)</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>85.8474</td>\n",
       "      <td>698.9147</td>\n",
       "      <td>45.8957</td>\n",
       "      <td>46</td>\n",
       "      <td>10.7477</td>\n",
       "      <td>29.6913</td>\n",
       "      <td>412.1663</td>\n",
       "      <td>46.8523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056984</td>\n",
       "      <td>-0.011507</td>\n",
       "      <td>-0.012932</td>\n",
       "      <td>-0.146292</td>\n",
       "      <td>-0.092129</td>\n",
       "      <td>0.043186</td>\n",
       "      <td>-0.027985</td>\n",
       "      <td>0.149890</td>\n",
       "      <td>-0.223297</td>\n",
       "      <td>EO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>88.3727</td>\n",
       "      <td>678.9429</td>\n",
       "      <td>23.8804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.6837</td>\n",
       "      <td>314.3801</td>\n",
       "      <td>87.1339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122560</td>\n",
       "      <td>0.161338</td>\n",
       "      <td>0.057577</td>\n",
       "      <td>-0.289226</td>\n",
       "      <td>-0.217620</td>\n",
       "      <td>0.383177</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.032459</td>\n",
       "      <td>-0.190202</td>\n",
       "      <td>EO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.4924</td>\n",
       "      <td>754.7887</td>\n",
       "      <td>50.0888</td>\n",
       "      <td>71</td>\n",
       "      <td>17.4877</td>\n",
       "      <td>37.8050</td>\n",
       "      <td>612.5444</td>\n",
       "      <td>45.8684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046685</td>\n",
       "      <td>-0.019545</td>\n",
       "      <td>0.027443</td>\n",
       "      <td>-0.189588</td>\n",
       "      <td>-0.051164</td>\n",
       "      <td>-0.099272</td>\n",
       "      <td>0.204298</td>\n",
       "      <td>-0.104940</td>\n",
       "      <td>-0.129108</td>\n",
       "      <td>EO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>78.8327</td>\n",
       "      <td>761.1057</td>\n",
       "      <td>41.4575</td>\n",
       "      <td>27</td>\n",
       "      <td>6.4593</td>\n",
       "      <td>27.0164</td>\n",
       "      <td>446.1722</td>\n",
       "      <td>64.1144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123047</td>\n",
       "      <td>-0.082896</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.084082</td>\n",
       "      <td>0.130780</td>\n",
       "      <td>-0.106925</td>\n",
       "      <td>-0.011477</td>\n",
       "      <td>0.081186</td>\n",
       "      <td>0.023819</td>\n",
       "      <td>EO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>63.3055</td>\n",
       "      <td>947.7851</td>\n",
       "      <td>40.0863</td>\n",
       "      <td>54</td>\n",
       "      <td>16.0714</td>\n",
       "      <td>35.2921</td>\n",
       "      <td>367.0269</td>\n",
       "      <td>49.2067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>-0.016011</td>\n",
       "      <td>-0.124211</td>\n",
       "      <td>-0.350270</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>0.022838</td>\n",
       "      <td>-0.058616</td>\n",
       "      <td>-0.242430</td>\n",
       "      <td>0.117196</td>\n",
       "      <td>EO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>36</td>\n",
       "      <td>Male</td>\n",
       "      <td>84.3914</td>\n",
       "      <td>710.9727</td>\n",
       "      <td>20.4221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14.9740</td>\n",
       "      <td>254.1884</td>\n",
       "      <td>78.5750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156168</td>\n",
       "      <td>-0.003896</td>\n",
       "      <td>0.084955</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>0.153955</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>-0.207500</td>\n",
       "      <td>0.055425</td>\n",
       "      <td>AC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>94.1723</td>\n",
       "      <td>637.1301</td>\n",
       "      <td>20.0847</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>14.0631</td>\n",
       "      <td>288.2414</td>\n",
       "      <td>70.0306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064413</td>\n",
       "      <td>-0.049778</td>\n",
       "      <td>-0.059893</td>\n",
       "      <td>-0.438174</td>\n",
       "      <td>-0.144314</td>\n",
       "      <td>-0.037145</td>\n",
       "      <td>-0.016475</td>\n",
       "      <td>-0.399745</td>\n",
       "      <td>-0.129649</td>\n",
       "      <td>AC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>92.8401</td>\n",
       "      <td>646.2725</td>\n",
       "      <td>24.3686</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>16.4590</td>\n",
       "      <td>304.7617</td>\n",
       "      <td>62.9154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177345</td>\n",
       "      <td>0.114239</td>\n",
       "      <td>0.180824</td>\n",
       "      <td>0.150073</td>\n",
       "      <td>0.099037</td>\n",
       "      <td>0.148904</td>\n",
       "      <td>0.119568</td>\n",
       "      <td>0.079116</td>\n",
       "      <td>0.105819</td>\n",
       "      <td>AC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "      <td>64.9858</td>\n",
       "      <td>923.2791</td>\n",
       "      <td>75.4837</td>\n",
       "      <td>221</td>\n",
       "      <td>66.1677</td>\n",
       "      <td>91.7459</td>\n",
       "      <td>1916.9640</td>\n",
       "      <td>37.0442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230870</td>\n",
       "      <td>0.205814</td>\n",
       "      <td>0.108824</td>\n",
       "      <td>0.273889</td>\n",
       "      <td>0.152374</td>\n",
       "      <td>0.344771</td>\n",
       "      <td>0.225022</td>\n",
       "      <td>0.275262</td>\n",
       "      <td>0.102648</td>\n",
       "      <td>AC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>85.8861</td>\n",
       "      <td>698.5996</td>\n",
       "      <td>25.9153</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2048</td>\n",
       "      <td>20.7255</td>\n",
       "      <td>397.8391</td>\n",
       "      <td>63.7022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>-0.224065</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>-0.242306</td>\n",
       "      <td>-0.024302</td>\n",
       "      <td>-0.396243</td>\n",
       "      <td>-0.129856</td>\n",
       "      <td>-0.462991</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>AC2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject NO.  Gender  Mean HR (BPM)  AVNN (ms)  SDNN (ms)  NN50 (beats)  \\\n",
       "0              1  Female        85.8474   698.9147    45.8957            46   \n",
       "1              2  Female        88.3727   678.9429    23.8804             0   \n",
       "2              3  Female        79.4924   754.7887    50.0888            71   \n",
       "3              4  Female        78.8327   761.1057    41.4575            27   \n",
       "4              5  Female        63.3055   947.7851    40.0863            54   \n",
       "..           ...     ...            ...        ...        ...           ...   \n",
       "115           36    Male        84.3914   710.9727    20.4221             0   \n",
       "116           37    Male        94.1723   637.1301    20.0847             2   \n",
       "117           38  Female        92.8401   646.2725    24.3686             3   \n",
       "118           39    Male        64.9858   923.2791    75.4837           221   \n",
       "119           40    Male        85.8861   698.5996    25.9153             5   \n",
       "\n",
       "     pNN50 (%)  RMSSD (ms)   LF (ms2)  LF Norm (n.u.)  ...  Alpha_(P 3 - P 4)  \\\n",
       "0      10.7477     29.6913   412.1663         46.8523  ...          -0.056984   \n",
       "1       0.0000     11.6837   314.3801         87.1339  ...          -0.122560   \n",
       "2      17.4877     37.8050   612.5444         45.8684  ...          -0.046685   \n",
       "3       6.4593     27.0164   446.1722         64.1144  ...           0.123047   \n",
       "4      16.0714     35.2921   367.0269         49.2067  ...           0.017300   \n",
       "..         ...         ...        ...             ...  ...                ...   \n",
       "115     0.0000     14.9740   254.1884         78.5750  ...           0.156168   \n",
       "116     0.3854     14.0631   288.2414         70.0306  ...          -0.064413   \n",
       "117     0.6024     16.4590   304.7617         62.9154  ...           0.177345   \n",
       "118    66.1677     91.7459  1916.9640         37.0442  ...           0.230870   \n",
       "119     1.2048     20.7255   397.8391         63.7022  ...           0.023985   \n",
       "\n",
       "     Beta1_(Fp 1 - Fp 2)  Beta1_(F 3 - F 4)  Beta1_(T 3 - T 4)  \\\n",
       "0              -0.011507          -0.012932          -0.146292   \n",
       "1               0.161338           0.057577          -0.289226   \n",
       "2              -0.019545           0.027443          -0.189588   \n",
       "3              -0.082896           0.019006           0.084082   \n",
       "4              -0.016011          -0.124211          -0.350270   \n",
       "..                   ...                ...                ...   \n",
       "115            -0.003896           0.084955           0.133143   \n",
       "116            -0.049778          -0.059893          -0.438174   \n",
       "117             0.114239           0.180824           0.150073   \n",
       "118             0.205814           0.108824           0.273889   \n",
       "119            -0.224065           0.002482          -0.242306   \n",
       "\n",
       "     Beta1_(P 3 - P 4)  Beta2_(Fp 1 - Fp 2)  Beta2_(F 3 - F 4)  \\\n",
       "0            -0.092129             0.043186          -0.027985   \n",
       "1            -0.217620             0.383177           0.005490   \n",
       "2            -0.051164            -0.099272           0.204298   \n",
       "3             0.130780            -0.106925          -0.011477   \n",
       "4            -0.000317             0.022838          -0.058616   \n",
       "..                 ...                  ...                ...   \n",
       "115           0.153955             0.011932           0.008967   \n",
       "116          -0.144314            -0.037145          -0.016475   \n",
       "117           0.099037             0.148904           0.119568   \n",
       "118           0.152374             0.344771           0.225022   \n",
       "119          -0.024302            -0.396243          -0.129856   \n",
       "\n",
       "     Beta2_(T 3 - T 4)  Beta2_(P 3 - P 4)  Segment  \n",
       "0             0.149890          -0.223297       EO  \n",
       "1             0.032459          -0.190202       EO  \n",
       "2            -0.104940          -0.129108       EO  \n",
       "3             0.081186           0.023819       EO  \n",
       "4            -0.242430           0.117196       EO  \n",
       "..                 ...                ...      ...  \n",
       "115          -0.207500           0.055425      AC2  \n",
       "116          -0.399745          -0.129649      AC2  \n",
       "117           0.079116           0.105819      AC2  \n",
       "118           0.275262           0.102648      AC2  \n",
       "119          -0.462991          -0.023000      AC2  \n",
       "\n",
       "[120 rows x 82 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all genders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eo vs ac1,ac2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.3733 - loss: 0.8655 - val_accuracy: 0.6667 - val_loss: 0.8587 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6178 - loss: 0.8556 - val_accuracy: 0.6389 - val_loss: 0.8537 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6894 - loss: 0.8525 - val_accuracy: 0.6389 - val_loss: 0.8490 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7000 - loss: 0.8454 - val_accuracy: 0.6667 - val_loss: 0.8445 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6564 - loss: 0.8410 - val_accuracy: 0.6667 - val_loss: 0.8397 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6790 - loss: 0.8374 - val_accuracy: 0.6667 - val_loss: 0.8349 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7263 - loss: 0.8313 - val_accuracy: 0.6667 - val_loss: 0.8302 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6400 - loss: 0.8267 - val_accuracy: 0.6667 - val_loss: 0.8253 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6631 - loss: 0.8219 - val_accuracy: 0.6667 - val_loss: 0.8202 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6732 - loss: 0.8173 - val_accuracy: 0.6667 - val_loss: 0.8150 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6597 - loss: 0.8106 - val_accuracy: 0.6667 - val_loss: 0.8094 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5564 - loss: 0.8125 - val_accuracy: 0.6667 - val_loss: 0.8037 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6924 - loss: 0.7963 - val_accuracy: 0.6667 - val_loss: 0.7974 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6385 - loss: 0.7927 - val_accuracy: 0.6667 - val_loss: 0.7911 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6854 - loss: 0.7830 - val_accuracy: 0.6667 - val_loss: 0.7841 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6676 - loss: 0.7768 - val_accuracy: 0.6667 - val_loss: 0.7767 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6765 - loss: 0.7660 - val_accuracy: 0.6667 - val_loss: 0.7686 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6753 - loss: 0.7603 - val_accuracy: 0.6667 - val_loss: 0.7597 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7434 - loss: 0.7356 - val_accuracy: 0.6667 - val_loss: 0.7500 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7529 - loss: 0.7169 - val_accuracy: 0.6667 - val_loss: 0.7394 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7136 - loss: 0.7127 - val_accuracy: 0.6667 - val_loss: 0.7282 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6794 - loss: 0.7129 - val_accuracy: 0.6667 - val_loss: 0.7156 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7021 - loss: 0.6844 - val_accuracy: 0.6389 - val_loss: 0.7008 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7035 - loss: 0.6732 - val_accuracy: 0.6389 - val_loss: 0.6849 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7471 - loss: 0.6331 - val_accuracy: 0.6389 - val_loss: 0.6687 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7295 - loss: 0.6262 - val_accuracy: 0.6111 - val_loss: 0.6522 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7002 - loss: 0.6254 - val_accuracy: 0.6111 - val_loss: 0.6364 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7623 - loss: 0.6110 - val_accuracy: 0.6389 - val_loss: 0.6214 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7794 - loss: 0.5651 - val_accuracy: 0.6389 - val_loss: 0.6078 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7979 - loss: 0.5101 - val_accuracy: 0.6944 - val_loss: 0.5956 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7861 - loss: 0.5273 - val_accuracy: 0.7500 - val_loss: 0.5858 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8027 - loss: 0.4954 - val_accuracy: 0.7778 - val_loss: 0.5773 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8565 - loss: 0.4837 - val_accuracy: 0.7778 - val_loss: 0.5705 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8522 - loss: 0.4857 - val_accuracy: 0.7778 - val_loss: 0.5648 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8718 - loss: 0.4780 - val_accuracy: 0.7500 - val_loss: 0.5588 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8555 - loss: 0.4626 - val_accuracy: 0.7500 - val_loss: 0.5537 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9287 - loss: 0.4284 - val_accuracy: 0.7500 - val_loss: 0.5480 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8172 - loss: 0.4827 - val_accuracy: 0.7500 - val_loss: 0.5437 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8514 - loss: 0.4543 - val_accuracy: 0.7500 - val_loss: 0.5388 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8175 - loss: 0.4711 - val_accuracy: 0.7500 - val_loss: 0.5345 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8455 - loss: 0.4671 - val_accuracy: 0.7500 - val_loss: 0.5288 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8967 - loss: 0.4296 - val_accuracy: 0.7500 - val_loss: 0.5239 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8822 - loss: 0.4057 - val_accuracy: 0.7500 - val_loss: 0.5197 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8767 - loss: 0.3976 - val_accuracy: 0.7500 - val_loss: 0.5177 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8696 - loss: 0.4044 - val_accuracy: 0.7500 - val_loss: 0.5148 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8465 - loss: 0.4173 - val_accuracy: 0.7778 - val_loss: 0.5090 - learning_rate: 3.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8611 - loss: 0.3825 - val_accuracy: 0.7778 - val_loss: 0.5040 - learning_rate: 3.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8926 - loss: 0.3701 - val_accuracy: 0.7778 - val_loss: 0.5007 - learning_rate: 3.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8960 - loss: 0.3759 - val_accuracy: 0.7778 - val_loss: 0.4990 - learning_rate: 3.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8953 - loss: 0.3680 - val_accuracy: 0.7778 - val_loss: 0.4948 - learning_rate: 3.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8960 - loss: 0.3799 - val_accuracy: 0.7778 - val_loss: 0.4906 - learning_rate: 3.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8762 - loss: 0.4082 - val_accuracy: 0.7778 - val_loss: 0.4884 - learning_rate: 3.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9161 - loss: 0.3542 - val_accuracy: 0.8056 - val_loss: 0.4828 - learning_rate: 3.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9049 - loss: 0.3765 - val_accuracy: 0.8056 - val_loss: 0.4768 - learning_rate: 3.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9000 - loss: 0.3371 - val_accuracy: 0.8056 - val_loss: 0.4716 - learning_rate: 3.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9198 - loss: 0.3109 - val_accuracy: 0.8056 - val_loss: 0.4675 - learning_rate: 3.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8982 - loss: 0.3690 - val_accuracy: 0.8056 - val_loss: 0.4617 - learning_rate: 3.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9183 - loss: 0.3346 - val_accuracy: 0.8056 - val_loss: 0.4519 - learning_rate: 3.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9027 - loss: 0.3170 - val_accuracy: 0.8056 - val_loss: 0.4425 - learning_rate: 3.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9138 - loss: 0.3379 - val_accuracy: 0.8056 - val_loss: 0.4337 - learning_rate: 3.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8841 - loss: 0.2890 - val_accuracy: 0.8056 - val_loss: 0.4280 - learning_rate: 3.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9294 - loss: 0.3187 - val_accuracy: 0.8333 - val_loss: 0.4186 - learning_rate: 3.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8826 - loss: 0.3572 - val_accuracy: 0.8333 - val_loss: 0.4105 - learning_rate: 3.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8766 - loss: 0.3692 - val_accuracy: 0.8333 - val_loss: 0.4061 - learning_rate: 3.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8945 - loss: 0.3024 - val_accuracy: 0.8333 - val_loss: 0.4018 - learning_rate: 3.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9243 - loss: 0.2687 - val_accuracy: 0.8889 - val_loss: 0.3973 - learning_rate: 3.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8722 - loss: 0.3313 - val_accuracy: 0.8889 - val_loss: 0.3924 - learning_rate: 3.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9531 - loss: 0.2704 - val_accuracy: 0.8611 - val_loss: 0.3903 - learning_rate: 3.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8974 - loss: 0.3978 - val_accuracy: 0.8611 - val_loss: 0.3884 - learning_rate: 3.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9599 - loss: 0.2575 - val_accuracy: 0.8611 - val_loss: 0.3861 - learning_rate: 3.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9666 - loss: 0.2381 - val_accuracy: 0.8611 - val_loss: 0.3823 - learning_rate: 3.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8908 - loss: 0.3054 - val_accuracy: 0.8889 - val_loss: 0.3792 - learning_rate: 3.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9089 - loss: 0.2794 - val_accuracy: 0.8889 - val_loss: 0.3760 - learning_rate: 3.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9413 - loss: 0.2474 - val_accuracy: 0.8889 - val_loss: 0.3698 - learning_rate: 3.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9347 - loss: 0.2794 - val_accuracy: 0.8889 - val_loss: 0.3670 - learning_rate: 3.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9146 - loss: 0.2806 - val_accuracy: 0.8889 - val_loss: 0.3664 - learning_rate: 3.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9592 - loss: 0.2436 - val_accuracy: 0.8889 - val_loss: 0.3663 - learning_rate: 3.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9456 - loss: 0.2467 - val_accuracy: 0.8889 - val_loss: 0.3655 - learning_rate: 3.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9280 - loss: 0.2329 - val_accuracy: 0.8889 - val_loss: 0.3653 - learning_rate: 3.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9045 - loss: 0.2537 - val_accuracy: 0.8889 - val_loss: 0.3624 - learning_rate: 3.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9421 - loss: 0.2681 - val_accuracy: 0.8889 - val_loss: 0.3534 - learning_rate: 3.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9539 - loss: 0.2795 - val_accuracy: 0.8889 - val_loss: 0.3482 - learning_rate: 3.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9368 - loss: 0.2386 - val_accuracy: 0.8889 - val_loss: 0.3434 - learning_rate: 3.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9453 - loss: 0.2733 - val_accuracy: 0.8889 - val_loss: 0.3404 - learning_rate: 3.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.2486 - val_accuracy: 0.8889 - val_loss: 0.3455 - learning_rate: 3.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9294 - loss: 0.2549 - val_accuracy: 0.8889 - val_loss: 0.3509 - learning_rate: 3.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9932 - loss: 0.2025 - val_accuracy: 0.8611 - val_loss: 0.3593 - learning_rate: 3.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9718 - loss: 0.2119 - val_accuracy: 0.8611 - val_loss: 0.3591 - learning_rate: 3.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9673 - loss: 0.2276 - val_accuracy: 0.8889 - val_loss: 0.3503 - learning_rate: 3.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9227 - loss: 0.2553 - val_accuracy: 0.8889 - val_loss: 0.3489 - learning_rate: 1.5000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.1941 - val_accuracy: 0.8889 - val_loss: 0.3456 - learning_rate: 1.5000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.2130 - val_accuracy: 0.8611 - val_loss: 0.3434 - learning_rate: 1.5000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9472 - loss: 0.2501 - val_accuracy: 0.8611 - val_loss: 0.3415 - learning_rate: 1.5000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.2170 - val_accuracy: 0.8889 - val_loss: 0.3412 - learning_rate: 1.5000e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375ms/step\n",
      "Improved Binary Classification Accuracy with RFE: 0.8888888888888888\n",
      "Improved Binary Classification F1 Score with RFE: 0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "\n",
    "X = combined_data.drop(columns=['Segment', 'Subject NO.', 'Gender'])\n",
    "y_binary = combined_data['Segment'].apply(lambda x: 0 if x == 'EO' else 1)\n",
    "\n",
    "# Feature Scaling for RFE\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply Recursive Feature Elimination (RFE)\n",
    "logistic_model = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "rfe = RFE(logistic_model, n_features_to_select=15)  \n",
    "rfe = rfe.fit(X_scaled, y_binary)\n",
    "\n",
    "# Select the features chosen by RFE\n",
    "X_rfe_selected = X_scaled[:, rfe.support_]\n",
    "\n",
    "\n",
    "X_train_rfe, X_test_rfe, y_train, y_test = train_test_split(X_rfe_selected, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "# Reshape the selected data for LSTM input [samples, timesteps, features]\n",
    "X_train_lstm_rfe = X_train_rfe.reshape((X_train_rfe.shape[0], 1, X_train_rfe.shape[1]))\n",
    "X_test_lstm_rfe = X_test_rfe.reshape((X_test_rfe.shape[0], 1, X_test_rfe.shape[1]))\n",
    "\n",
    "# Build an improved Hybrid LSTM + NN Model using the selected features\n",
    "model = Sequential()\n",
    "\n",
    "# Bidirectional LSTM Layer with max_norm constraint to prevent exploding gradients\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_constraint=max_norm(3)), input_shape=(X_train_lstm_rfe.shape[1], X_train_lstm_rfe.shape[2])))\n",
    "model.add(Dropout(0.5))  # Increased Dropout rate to reduce overfitting\n",
    "\n",
    "# Second LSTM Layer for added depth\n",
    "model.add(LSTM(64, return_sequences=False, kernel_constraint=max_norm(3)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Fully Connected (Dense) Layers with L2 regularization and Dropout\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output Layer (sigmoid for binary classification)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the Model with Adam optimizer and a smaller learning rate\n",
    "optimizer = Adam(learning_rate=0.0003, clipvalue=1.0)  # Gradient clipping added\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model for more epochs with smaller batch size and callbacks\n",
    "model.fit(X_train_lstm_rfe, y_train, epochs=150, batch_size=16, verbose=1, validation_data=(X_test_lstm_rfe, y_test), \n",
    "          callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "binary_predictions = model.predict(X_test_lstm_rfe)\n",
    "binary_predictions = (binary_predictions > 0.5).astype(int)\n",
    "\n",
    "binary_acc = accuracy_score(y_test, binary_predictions)\n",
    "binary_f1 = f1_score(y_test, binary_predictions)\n",
    "\n",
    "print(f\"Improved Binary Classification Accuracy with RFE: {binary_acc}\")\n",
    "print(f\"Improved Binary Classification F1 Score with RFE: {binary_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features by RFE:\n",
      "Index(['Mean HR (BPM)', 'pNN50 (%)', 'HF Norm (n.u.)', 'Fp1_Theta (4-8 Hz)',\n",
      "       'Fp2_Theta (4-8 Hz)', 'F3_Alpha (8-12 Hz)', 'F4_Alpha (8-12 Hz)',\n",
      "       'P4_Alpha (8-12 Hz)', 'F3_Beta 2 (20-30 Hz)', 'Fp1_Gamma (30-60 Hz)',\n",
      "       'P4_Gamma (30-60 Hz)', 'Fp1_Gamma 2 (60-100 Hz)', 'Beta1_(Fp 1 - Fp 2)',\n",
      "       'Beta1_(T 3 - T 4)', 'Beta1_(P 3 - P 4)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features by RFE:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The selected features from RFE are distributed across the files as follows:\n",
    "\n",
    "# ECG Data: 3 features\n",
    "# EEG Data: 9 features\n",
    "# Ratio of Alpha/Beta Power Data: 3 features\n",
    "# This shows that most of the important features selected by RFE come from the EEG data, with a few from ECG and ratio data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eo vs ac1\n",
    "## eo vs ac2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - accuracy: 0.4702 - loss: 0.8622 - val_accuracy: 0.5000 - val_loss: 0.8630 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3997 - loss: 0.8622 - val_accuracy: 0.5417 - val_loss: 0.8606 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3890 - loss: 0.8618 - val_accuracy: 0.5417 - val_loss: 0.8582 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5134 - loss: 0.8585 - val_accuracy: 0.6250 - val_loss: 0.8557 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5289 - loss: 0.8567 - val_accuracy: 0.6250 - val_loss: 0.8535 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5488 - loss: 0.8506 - val_accuracy: 0.6667 - val_loss: 0.8513 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7259 - loss: 0.8461 - val_accuracy: 0.6250 - val_loss: 0.8493 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4762 - loss: 0.8503 - val_accuracy: 0.6250 - val_loss: 0.8472 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5598 - loss: 0.8456 - val_accuracy: 0.5833 - val_loss: 0.8452 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6696 - loss: 0.8416 - val_accuracy: 0.5833 - val_loss: 0.8431 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6810 - loss: 0.8376 - val_accuracy: 0.5833 - val_loss: 0.8409 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7080 - loss: 0.8336 - val_accuracy: 0.5833 - val_loss: 0.8387 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6158 - loss: 0.8339 - val_accuracy: 0.5833 - val_loss: 0.8364 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7193 - loss: 0.8314 - val_accuracy: 0.5833 - val_loss: 0.8342 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6905 - loss: 0.8253 - val_accuracy: 0.6250 - val_loss: 0.8318 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5943 - loss: 0.8278 - val_accuracy: 0.6250 - val_loss: 0.8294 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6542 - loss: 0.8259 - val_accuracy: 0.6250 - val_loss: 0.8269 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6744 - loss: 0.8235 - val_accuracy: 0.6250 - val_loss: 0.8245 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6414 - loss: 0.8203 - val_accuracy: 0.6250 - val_loss: 0.8218 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7045 - loss: 0.8100 - val_accuracy: 0.6250 - val_loss: 0.8190 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6932 - loss: 0.8082 - val_accuracy: 0.6250 - val_loss: 0.8160 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6640 - loss: 0.8051 - val_accuracy: 0.6250 - val_loss: 0.8132 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6330 - loss: 0.8083 - val_accuracy: 0.6667 - val_loss: 0.8100 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7250 - loss: 0.8019 - val_accuracy: 0.6667 - val_loss: 0.8066 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7015 - loss: 0.8009 - val_accuracy: 0.6667 - val_loss: 0.8032 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6670 - loss: 0.7986 - val_accuracy: 0.6667 - val_loss: 0.7999 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6327 - loss: 0.7934 - val_accuracy: 0.6667 - val_loss: 0.7965 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7396 - loss: 0.7843 - val_accuracy: 0.6667 - val_loss: 0.7929 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6607 - loss: 0.7713 - val_accuracy: 0.6667 - val_loss: 0.7893 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6798 - loss: 0.7708 - val_accuracy: 0.6667 - val_loss: 0.7857 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7964 - loss: 0.7655 - val_accuracy: 0.7083 - val_loss: 0.7818 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7366 - loss: 0.7517 - val_accuracy: 0.7083 - val_loss: 0.7782 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7646 - loss: 0.7459 - val_accuracy: 0.7083 - val_loss: 0.7749 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7604 - loss: 0.7367 - val_accuracy: 0.7083 - val_loss: 0.7720 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7997 - loss: 0.7229 - val_accuracy: 0.7083 - val_loss: 0.7694 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7789 - loss: 0.7132 - val_accuracy: 0.7083 - val_loss: 0.7669 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7437 - loss: 0.7078 - val_accuracy: 0.7083 - val_loss: 0.7649 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7292 - loss: 0.7084 - val_accuracy: 0.7083 - val_loss: 0.7633 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7092 - loss: 0.6978 - val_accuracy: 0.7500 - val_loss: 0.7615 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7208 - loss: 0.6741 - val_accuracy: 0.7500 - val_loss: 0.7602 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8372 - loss: 0.6388 - val_accuracy: 0.7500 - val_loss: 0.7604 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7801 - loss: 0.6696 - val_accuracy: 0.7500 - val_loss: 0.7609 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8265 - loss: 0.6354 - val_accuracy: 0.7917 - val_loss: 0.7620 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8235 - loss: 0.6234 - val_accuracy: 0.7917 - val_loss: 0.7614 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8060 - loss: 0.6142 - val_accuracy: 0.7917 - val_loss: 0.7629 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7911 - loss: 0.5983 - val_accuracy: 0.7917 - val_loss: 0.7624 - learning_rate: 1.5000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8399 - loss: 0.5967 - val_accuracy: 0.7917 - val_loss: 0.7603 - learning_rate: 1.5000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7789 - loss: 0.5943 - val_accuracy: 0.7917 - val_loss: 0.7589 - learning_rate: 1.5000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7943 - loss: 0.5998 - val_accuracy: 0.7917 - val_loss: 0.7567 - learning_rate: 1.5000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8381 - loss: 0.5915 - val_accuracy: 0.7917 - val_loss: 0.7555 - learning_rate: 1.5000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7964 - loss: 0.6010 - val_accuracy: 0.7917 - val_loss: 0.7539 - learning_rate: 1.5000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8330 - loss: 0.5378 - val_accuracy: 0.7917 - val_loss: 0.7518 - learning_rate: 1.5000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8628 - loss: 0.5458 - val_accuracy: 0.7917 - val_loss: 0.7507 - learning_rate: 1.5000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8006 - loss: 0.5707 - val_accuracy: 0.7917 - val_loss: 0.7495 - learning_rate: 1.5000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8536 - loss: 0.5266 - val_accuracy: 0.7917 - val_loss: 0.7486 - learning_rate: 1.5000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8574 - loss: 0.5628 - val_accuracy: 0.7917 - val_loss: 0.7485 - learning_rate: 1.5000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8586 - loss: 0.5589 - val_accuracy: 0.7917 - val_loss: 0.7487 - learning_rate: 1.5000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8470 - loss: 0.5206 - val_accuracy: 0.7917 - val_loss: 0.7500 - learning_rate: 1.5000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8408 - loss: 0.5246 - val_accuracy: 0.7500 - val_loss: 0.7512 - learning_rate: 1.5000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8336 - loss: 0.5043 - val_accuracy: 0.7500 - val_loss: 0.7539 - learning_rate: 1.5000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8357 - loss: 0.5137 - val_accuracy: 0.7500 - val_loss: 0.7559 - learning_rate: 1.5000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8866 - loss: 0.4713 - val_accuracy: 0.7500 - val_loss: 0.7568 - learning_rate: 7.5000e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9095 - loss: 0.4432 - val_accuracy: 0.7500 - val_loss: 0.7568 - learning_rate: 7.5000e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8637 - loss: 0.4928 - val_accuracy: 0.7500 - val_loss: 0.7571 - learning_rate: 7.5000e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8783 - loss: 0.4924 - val_accuracy: 0.7500 - val_loss: 0.7582 - learning_rate: 7.5000e-05\n",
      "Epoch 66/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8509 - loss: 0.5169 - val_accuracy: 0.7500 - val_loss: 0.7593 - learning_rate: 7.5000e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
      "All Genders - EO vs AC1 Accuracy: 0.7916666666666666, F1 Score: 0.7619047619047619\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.5452 - loss: 0.8639 - val_accuracy: 0.5000 - val_loss: 0.8626 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3911 - loss: 0.8635 - val_accuracy: 0.5000 - val_loss: 0.8600 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5682 - loss: 0.8579 - val_accuracy: 0.5417 - val_loss: 0.8576 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4946 - loss: 0.8576 - val_accuracy: 0.5417 - val_loss: 0.8551 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5577 - loss: 0.8538 - val_accuracy: 0.5417 - val_loss: 0.8527 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5940 - loss: 0.8502 - val_accuracy: 0.5417 - val_loss: 0.8501 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5402 - loss: 0.8507 - val_accuracy: 0.5417 - val_loss: 0.8475 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6137 - loss: 0.8474 - val_accuracy: 0.5833 - val_loss: 0.8449 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6973 - loss: 0.8443 - val_accuracy: 0.5833 - val_loss: 0.8422 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7119 - loss: 0.8398 - val_accuracy: 0.5833 - val_loss: 0.8395 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6943 - loss: 0.8368 - val_accuracy: 0.5833 - val_loss: 0.8367 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5783 - loss: 0.8387 - val_accuracy: 0.5833 - val_loss: 0.8338 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6705 - loss: 0.8309 - val_accuracy: 0.6667 - val_loss: 0.8307 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6324 - loss: 0.8323 - val_accuracy: 0.6667 - val_loss: 0.8275 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6586 - loss: 0.8285 - val_accuracy: 0.6667 - val_loss: 0.8240 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6952 - loss: 0.8207 - val_accuracy: 0.7083 - val_loss: 0.8202 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7366 - loss: 0.8192 - val_accuracy: 0.7083 - val_loss: 0.8163 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6753 - loss: 0.8176 - val_accuracy: 0.7500 - val_loss: 0.8119 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7074 - loss: 0.8136 - val_accuracy: 0.7500 - val_loss: 0.8071 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7324 - loss: 0.8081 - val_accuracy: 0.7500 - val_loss: 0.8017 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7655 - loss: 0.8036 - val_accuracy: 0.7500 - val_loss: 0.7958 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7580 - loss: 0.7985 - val_accuracy: 0.7500 - val_loss: 0.7893 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8628 - loss: 0.7820 - val_accuracy: 0.7500 - val_loss: 0.7821 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8283 - loss: 0.7816 - val_accuracy: 0.7500 - val_loss: 0.7742 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8077 - loss: 0.7763 - val_accuracy: 0.7500 - val_loss: 0.7653 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8211 - loss: 0.7718 - val_accuracy: 0.7500 - val_loss: 0.7561 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8804 - loss: 0.7605 - val_accuracy: 0.7500 - val_loss: 0.7455 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8220 - loss: 0.7511 - val_accuracy: 0.7500 - val_loss: 0.7343 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8708 - loss: 0.7375 - val_accuracy: 0.7500 - val_loss: 0.7219 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8783 - loss: 0.7081 - val_accuracy: 0.7500 - val_loss: 0.7079 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8461 - loss: 0.6936 - val_accuracy: 0.7917 - val_loss: 0.6926 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8687 - loss: 0.7008 - val_accuracy: 0.8333 - val_loss: 0.6764 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8595 - loss: 0.6797 - val_accuracy: 0.8333 - val_loss: 0.6597 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8750 - loss: 0.6419 - val_accuracy: 0.8333 - val_loss: 0.6421 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8696 - loss: 0.6266 - val_accuracy: 0.8333 - val_loss: 0.6252 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9155 - loss: 0.5859 - val_accuracy: 0.8333 - val_loss: 0.6088 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9214 - loss: 0.5670 - val_accuracy: 0.8333 - val_loss: 0.5916 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8946 - loss: 0.5577 - val_accuracy: 0.8333 - val_loss: 0.5741 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8914 - loss: 0.5554 - val_accuracy: 0.8333 - val_loss: 0.5569 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9039 - loss: 0.5270 - val_accuracy: 0.8333 - val_loss: 0.5419 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9164 - loss: 0.5206 - val_accuracy: 0.8333 - val_loss: 0.5288 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9298 - loss: 0.5128 - val_accuracy: 0.8333 - val_loss: 0.5193 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9360 - loss: 0.4466 - val_accuracy: 0.8333 - val_loss: 0.5100 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9173 - loss: 0.4564 - val_accuracy: 0.8333 - val_loss: 0.5016 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9527 - loss: 0.3986 - val_accuracy: 0.8333 - val_loss: 0.4958 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9536 - loss: 0.4132 - val_accuracy: 0.8333 - val_loss: 0.4891 - learning_rate: 3.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9661 - loss: 0.3516 - val_accuracy: 0.7917 - val_loss: 0.4850 - learning_rate: 3.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9298 - loss: 0.3919 - val_accuracy: 0.7917 - val_loss: 0.4832 - learning_rate: 3.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9339 - loss: 0.3816 - val_accuracy: 0.7917 - val_loss: 0.4793 - learning_rate: 3.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9423 - loss: 0.3515 - val_accuracy: 0.7917 - val_loss: 0.4748 - learning_rate: 3.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9223 - loss: 0.3916 - val_accuracy: 0.8333 - val_loss: 0.4686 - learning_rate: 3.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9702 - loss: 0.3131 - val_accuracy: 0.8333 - val_loss: 0.4654 - learning_rate: 3.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9702 - loss: 0.2860 - val_accuracy: 0.8333 - val_loss: 0.4649 - learning_rate: 3.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9399 - loss: 0.3674 - val_accuracy: 0.8333 - val_loss: 0.4581 - learning_rate: 3.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9473 - loss: 0.3098 - val_accuracy: 0.8333 - val_loss: 0.4555 - learning_rate: 3.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9286 - loss: 0.3070 - val_accuracy: 0.8333 - val_loss: 0.4573 - learning_rate: 3.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9649 - loss: 0.2998 - val_accuracy: 0.8333 - val_loss: 0.4637 - learning_rate: 3.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9485 - loss: 0.2829 - val_accuracy: 0.8750 - val_loss: 0.4682 - learning_rate: 3.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9048 - loss: 0.3533 - val_accuracy: 0.8750 - val_loss: 0.4683 - learning_rate: 3.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9411 - loss: 0.2605 - val_accuracy: 0.8750 - val_loss: 0.4690 - learning_rate: 3.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9402 - loss: 0.2693 - val_accuracy: 0.8750 - val_loss: 0.4727 - learning_rate: 1.5000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9524 - loss: 0.2727 - val_accuracy: 0.8750 - val_loss: 0.4771 - learning_rate: 1.5000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9598 - loss: 0.2847 - val_accuracy: 0.8750 - val_loss: 0.4778 - learning_rate: 1.5000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9557 - loss: 0.2489 - val_accuracy: 0.8750 - val_loss: 0.4744 - learning_rate: 1.5000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9774 - loss: 0.2561 - val_accuracy: 0.8750 - val_loss: 0.4779 - learning_rate: 1.5000e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step\n",
      "All Genders - EO vs AC2 Accuracy: 0.8333333333333334, F1 Score: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "def train_model_all_genders(segment_1, segment_2):\n",
    "    # Filter out data for the two segments (EO vs AC1 or EO vs AC2)\n",
    "    filtered_data = combined_data[combined_data['Segment'].isin([segment_1, segment_2])]\n",
    "    \n",
    "    # Create binary labels for classification (0 for EO, 1 for AC1 or AC2)\n",
    "    y_binary = filtered_data['Segment'].apply(lambda x: 0 if x == segment_1 else 1)\n",
    "    \n",
    "    X = filtered_data.drop(columns=['Segment', 'Subject NO.', 'Gender'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Apply Recursive Feature Elimination (RFE)\n",
    "    logistic_model = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "    rfe = RFE(logistic_model, n_features_to_select=15)  # Adjust the number of features\n",
    "    rfe = rfe.fit(X_scaled, y_binary)\n",
    "    \n",
    "    # Select the features chosen by RFE\n",
    "    X_rfe_selected = X_scaled[:, rfe.support_]\n",
    "    \n",
    "    X_train_rfe, X_test_rfe, y_train, y_test = train_test_split(X_rfe_selected, y_binary, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Reshape the selected data for LSTM input [samples, timesteps, features]\n",
    "    X_train_lstm_rfe = X_train_rfe.reshape((X_train_rfe.shape[0], 1, X_train_rfe.shape[1]))\n",
    "    X_test_lstm_rfe = X_test_rfe.reshape((X_test_rfe.shape[0], 1, X_test_rfe.shape[1]))\n",
    "    \n",
    "    # Build and compile the model (similar to the previous example)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_constraint=max_norm(3)), input_shape=(X_train_lstm_rfe.shape[1], X_train_lstm_rfe.shape[2])))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64, return_sequences=False, kernel_constraint=max_norm(3)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.0003, clipvalue=1.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # Learning rate scheduler and early stopping\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train_lstm_rfe, y_train, epochs=150, batch_size=16, verbose=1, validation_data=(X_test_lstm_rfe, y_test),\n",
    "                callbacks=[reduce_lr, early_stopping])\n",
    "    \n",
    "    binary_predictions = model.predict(X_test_lstm_rfe)\n",
    "    binary_predictions = (binary_predictions > 0.5).astype(int)\n",
    "    \n",
    "    binary_acc = accuracy_score(y_test, binary_predictions)\n",
    "    binary_f1 = f1_score(y_test, binary_predictions)\n",
    "    \n",
    "    print(f\"All Genders - {segment_1} vs {segment_2} Accuracy: {binary_acc}, F1 Score: {binary_f1}\")\n",
    "\n",
    "train_model_all_genders('EO', 'AC1')\n",
    "\n",
    "train_model_all_genders('EO', 'AC2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Males and Females"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EO VS AC1,AC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with RFE for Male...\n",
      "\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 259ms/step - accuracy: 0.6436 - loss: 0.8592 - val_accuracy: 0.5000 - val_loss: 0.8598 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7183 - loss: 0.8573 - val_accuracy: 0.5000 - val_loss: 0.8582 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7183 - loss: 0.8538 - val_accuracy: 0.5000 - val_loss: 0.8565 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7724 - loss: 0.8515 - val_accuracy: 0.5000 - val_loss: 0.8549 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7674 - loss: 0.8462 - val_accuracy: 0.5000 - val_loss: 0.8533 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7390 - loss: 0.8431 - val_accuracy: 0.5000 - val_loss: 0.8518 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8143 - loss: 0.8378 - val_accuracy: 0.5000 - val_loss: 0.8503 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6793 - loss: 0.8418 - val_accuracy: 0.5000 - val_loss: 0.8488 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7312 - loss: 0.8369 - val_accuracy: 0.5000 - val_loss: 0.8474 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7155 - loss: 0.8343 - val_accuracy: 0.5000 - val_loss: 0.8459 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6999 - loss: 0.8294 - val_accuracy: 0.5000 - val_loss: 0.8445 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7937 - loss: 0.8155 - val_accuracy: 0.5000 - val_loss: 0.8432 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7390 - loss: 0.8167 - val_accuracy: 0.5000 - val_loss: 0.8418 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7077 - loss: 0.8196 - val_accuracy: 0.5000 - val_loss: 0.8404 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7234 - loss: 0.8090 - val_accuracy: 0.5000 - val_loss: 0.8390 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7312 - loss: 0.8070 - val_accuracy: 0.5000 - val_loss: 0.8376 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7468 - loss: 0.7940 - val_accuracy: 0.5000 - val_loss: 0.8362 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7390 - loss: 0.7993 - val_accuracy: 0.5000 - val_loss: 0.8349 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7468 - loss: 0.7923 - val_accuracy: 0.5000 - val_loss: 0.8336 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7937 - loss: 0.7779 - val_accuracy: 0.5000 - val_loss: 0.8322 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7312 - loss: 0.7816 - val_accuracy: 0.5000 - val_loss: 0.8308 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7702 - loss: 0.7690 - val_accuracy: 0.5000 - val_loss: 0.8294 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7546 - loss: 0.7621 - val_accuracy: 0.5000 - val_loss: 0.8280 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7312 - loss: 0.7623 - val_accuracy: 0.5000 - val_loss: 0.8267 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7312 - loss: 0.7534 - val_accuracy: 0.5000 - val_loss: 0.8253 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7702 - loss: 0.7302 - val_accuracy: 0.5000 - val_loss: 0.8239 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7077 - loss: 0.7491 - val_accuracy: 0.5000 - val_loss: 0.8226 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7468 - loss: 0.7333 - val_accuracy: 0.5000 - val_loss: 0.8213 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6999 - loss: 0.7419 - val_accuracy: 0.5000 - val_loss: 0.8200 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7546 - loss: 0.7155 - val_accuracy: 0.5000 - val_loss: 0.8189 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7624 - loss: 0.7107 - val_accuracy: 0.5000 - val_loss: 0.8180 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7155 - loss: 0.7091 - val_accuracy: 0.5000 - val_loss: 0.8174 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7312 - loss: 0.6852 - val_accuracy: 0.5000 - val_loss: 0.8167 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7780 - loss: 0.6780 - val_accuracy: 0.5000 - val_loss: 0.8163 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7780 - loss: 0.6635 - val_accuracy: 0.5000 - val_loss: 0.8157 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7780 - loss: 0.6365 - val_accuracy: 0.5000 - val_loss: 0.8153 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6999 - loss: 0.6524 - val_accuracy: 0.5000 - val_loss: 0.8147 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7390 - loss: 0.6389 - val_accuracy: 0.5000 - val_loss: 0.8144 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7312 - loss: 0.6170 - val_accuracy: 0.5000 - val_loss: 0.8146 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7468 - loss: 0.6040 - val_accuracy: 0.5000 - val_loss: 0.8154 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7390 - loss: 0.6155 - val_accuracy: 0.5000 - val_loss: 0.8162 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7780 - loss: 0.5503 - val_accuracy: 0.5000 - val_loss: 0.8174 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8015 - loss: 0.5214 - val_accuracy: 0.5000 - val_loss: 0.8193 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7780 - loss: 0.5303 - val_accuracy: 0.5000 - val_loss: 0.8202 - learning_rate: 1.5000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7234 - loss: 0.5478 - val_accuracy: 0.5000 - val_loss: 0.8211 - learning_rate: 1.5000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7312 - loss: 0.5716 - val_accuracy: 0.5000 - val_loss: 0.8222 - learning_rate: 1.5000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7624 - loss: 0.5285 - val_accuracy: 0.5000 - val_loss: 0.8229 - learning_rate: 1.5000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7440 - loss: 0.5647 - val_accuracy: 0.5000 - val_loss: 0.8233 - learning_rate: 1.5000e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n",
      "Male Model - Accuracy with RFE: 0.5\n",
      "Male Model - F1 Score with RFE: 0.6666666666666666\n",
      "\n",
      "Training model with RFE for Female...\n",
      "\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 279ms/step - accuracy: 0.3494 - loss: 0.8666 - val_accuracy: 0.5789 - val_loss: 0.8603 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7195 - loss: 0.8570 - val_accuracy: 0.5789 - val_loss: 0.8579 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6307 - loss: 0.8545 - val_accuracy: 0.5789 - val_loss: 0.8556 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6925 - loss: 0.8549 - val_accuracy: 0.5789 - val_loss: 0.8533 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7152 - loss: 0.8485 - val_accuracy: 0.5789 - val_loss: 0.8511 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7386 - loss: 0.8469 - val_accuracy: 0.5789 - val_loss: 0.8489 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6839 - loss: 0.8446 - val_accuracy: 0.5789 - val_loss: 0.8467 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7663 - loss: 0.8373 - val_accuracy: 0.5789 - val_loss: 0.8444 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6648 - loss: 0.8371 - val_accuracy: 0.5789 - val_loss: 0.8421 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6882 - loss: 0.8365 - val_accuracy: 0.5789 - val_loss: 0.8397 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6768 - loss: 0.8323 - val_accuracy: 0.5789 - val_loss: 0.8374 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6648 - loss: 0.8256 - val_accuracy: 0.5789 - val_loss: 0.8349 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6413 - loss: 0.8268 - val_accuracy: 0.5789 - val_loss: 0.8323 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7351 - loss: 0.8123 - val_accuracy: 0.5789 - val_loss: 0.8297 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7116 - loss: 0.8135 - val_accuracy: 0.5789 - val_loss: 0.8270 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6960 - loss: 0.8078 - val_accuracy: 0.5789 - val_loss: 0.8243 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7351 - loss: 0.8064 - val_accuracy: 0.5789 - val_loss: 0.8214 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6804 - loss: 0.8042 - val_accuracy: 0.5789 - val_loss: 0.8185 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7273 - loss: 0.7952 - val_accuracy: 0.5789 - val_loss: 0.8155 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6960 - loss: 0.7994 - val_accuracy: 0.5789 - val_loss: 0.8123 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7116 - loss: 0.7870 - val_accuracy: 0.5789 - val_loss: 0.8090 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7195 - loss: 0.7843 - val_accuracy: 0.5789 - val_loss: 0.8054 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6804 - loss: 0.7821 - val_accuracy: 0.5789 - val_loss: 0.8016 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7273 - loss: 0.7678 - val_accuracy: 0.5789 - val_loss: 0.7976 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7273 - loss: 0.7604 - val_accuracy: 0.5789 - val_loss: 0.7934 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7585 - loss: 0.7471 - val_accuracy: 0.5789 - val_loss: 0.7889 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6570 - loss: 0.7633 - val_accuracy: 0.5789 - val_loss: 0.7842 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6804 - loss: 0.7546 - val_accuracy: 0.5789 - val_loss: 0.7793 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7116 - loss: 0.7294 - val_accuracy: 0.5789 - val_loss: 0.7741 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6918 - loss: 0.7387 - val_accuracy: 0.5789 - val_loss: 0.7686 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7116 - loss: 0.7293 - val_accuracy: 0.5789 - val_loss: 0.7628 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7074 - loss: 0.7056 - val_accuracy: 0.5789 - val_loss: 0.7563 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7308 - loss: 0.6834 - val_accuracy: 0.5789 - val_loss: 0.7493 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.6864 - val_accuracy: 0.6316 - val_loss: 0.7419 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7422 - loss: 0.6837 - val_accuracy: 0.6842 - val_loss: 0.7345 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7351 - loss: 0.6391 - val_accuracy: 0.6842 - val_loss: 0.7268 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7621 - loss: 0.6502 - val_accuracy: 0.6842 - val_loss: 0.7191 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7031 - loss: 0.6428 - val_accuracy: 0.6842 - val_loss: 0.7109 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7422 - loss: 0.6180 - val_accuracy: 0.6842 - val_loss: 0.7022 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7656 - loss: 0.6121 - val_accuracy: 0.7368 - val_loss: 0.6937 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7543 - loss: 0.5837 - val_accuracy: 0.7368 - val_loss: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7926 - loss: 0.5912 - val_accuracy: 0.7895 - val_loss: 0.6767 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8196 - loss: 0.5418 - val_accuracy: 0.7895 - val_loss: 0.6682 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7379 - loss: 0.5734 - val_accuracy: 0.7895 - val_loss: 0.6596 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8693 - loss: 0.5170 - val_accuracy: 0.7895 - val_loss: 0.6515 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8537 - loss: 0.5335 - val_accuracy: 0.7895 - val_loss: 0.6430 - learning_rate: 3.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7841 - loss: 0.5222 - val_accuracy: 0.7895 - val_loss: 0.6344 - learning_rate: 3.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9197 - loss: 0.4612 - val_accuracy: 0.7895 - val_loss: 0.6257 - learning_rate: 3.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8999 - loss: 0.4584 - val_accuracy: 0.7895 - val_loss: 0.6172 - learning_rate: 3.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8842 - loss: 0.4694 - val_accuracy: 0.7895 - val_loss: 0.6091 - learning_rate: 3.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8807 - loss: 0.4359 - val_accuracy: 0.7895 - val_loss: 0.6010 - learning_rate: 3.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8267 - loss: 0.4751 - val_accuracy: 0.7895 - val_loss: 0.5927 - learning_rate: 3.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9233 - loss: 0.3720 - val_accuracy: 0.7895 - val_loss: 0.5845 - learning_rate: 3.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9190 - loss: 0.4105 - val_accuracy: 0.7895 - val_loss: 0.5769 - learning_rate: 3.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9347 - loss: 0.3470 - val_accuracy: 0.7895 - val_loss: 0.5699 - learning_rate: 3.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8885 - loss: 0.3619 - val_accuracy: 0.7895 - val_loss: 0.5638 - learning_rate: 3.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9425 - loss: 0.3550 - val_accuracy: 0.7895 - val_loss: 0.5568 - learning_rate: 3.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9425 - loss: 0.3640 - val_accuracy: 0.7895 - val_loss: 0.5509 - learning_rate: 3.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9425 - loss: 0.3132 - val_accuracy: 0.7895 - val_loss: 0.5450 - learning_rate: 3.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9268 - loss: 0.3262 - val_accuracy: 0.7895 - val_loss: 0.5386 - learning_rate: 3.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9616 - loss: 0.3239 - val_accuracy: 0.7895 - val_loss: 0.5327 - learning_rate: 3.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9538 - loss: 0.3008 - val_accuracy: 0.7368 - val_loss: 0.5268 - learning_rate: 3.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9808 - loss: 0.2860 - val_accuracy: 0.7895 - val_loss: 0.5219 - learning_rate: 3.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9808 - loss: 0.2813 - val_accuracy: 0.7895 - val_loss: 0.5169 - learning_rate: 3.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.2781 - val_accuracy: 0.7895 - val_loss: 0.5122 - learning_rate: 3.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9652 - loss: 0.2837 - val_accuracy: 0.7895 - val_loss: 0.5077 - learning_rate: 3.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9808 - loss: 0.2457 - val_accuracy: 0.7895 - val_loss: 0.5034 - learning_rate: 3.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9652 - loss: 0.2793 - val_accuracy: 0.7895 - val_loss: 0.4996 - learning_rate: 3.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.2453 - val_accuracy: 0.7895 - val_loss: 0.4960 - learning_rate: 3.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.2264 - val_accuracy: 0.8421 - val_loss: 0.4931 - learning_rate: 3.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.2331 - val_accuracy: 0.8421 - val_loss: 0.4910 - learning_rate: 3.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.2085 - val_accuracy: 0.8421 - val_loss: 0.4889 - learning_rate: 3.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.2074 - val_accuracy: 0.8421 - val_loss: 0.4863 - learning_rate: 3.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.2192 - val_accuracy: 0.8947 - val_loss: 0.4854 - learning_rate: 3.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9652 - loss: 0.2171 - val_accuracy: 0.8421 - val_loss: 0.4827 - learning_rate: 3.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9886 - loss: 0.2001 - val_accuracy: 0.8421 - val_loss: 0.4796 - learning_rate: 3.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.1979 - val_accuracy: 0.8421 - val_loss: 0.4788 - learning_rate: 3.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.2152 - val_accuracy: 0.8421 - val_loss: 0.4783 - learning_rate: 3.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.1756 - val_accuracy: 0.8421 - val_loss: 0.4784 - learning_rate: 3.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1971 - val_accuracy: 0.8421 - val_loss: 0.4799 - learning_rate: 3.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.1818 - val_accuracy: 0.8421 - val_loss: 0.4818 - learning_rate: 3.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1701 - val_accuracy: 0.8421 - val_loss: 0.4839 - learning_rate: 3.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.1899 - val_accuracy: 0.8421 - val_loss: 0.4862 - learning_rate: 3.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1811 - val_accuracy: 0.8421 - val_loss: 0.4869 - learning_rate: 1.5000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9652 - loss: 0.1977 - val_accuracy: 0.8421 - val_loss: 0.4870 - learning_rate: 1.5000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1697 - val_accuracy: 0.8421 - val_loss: 0.4877 - learning_rate: 1.5000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9886 - loss: 0.1653 - val_accuracy: 0.8421 - val_loss: 0.4884 - learning_rate: 1.5000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1530 - val_accuracy: 0.8421 - val_loss: 0.4885 - learning_rate: 1.5000e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step\n",
      "Female Model - Accuracy with RFE: 0.8421052631578947\n",
      "Female Model - F1 Score with RFE: 0.8695652173913043\n",
      "\n",
      "Final Results with RFE:\n",
      "Male Model - Accuracy: 0.5, F1 Score: 0.6666666666666666\n",
      "Female Model - Accuracy: 0.8421052631578947, F1 Score: 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "def build_and_train_rfe_model_by_gender(gender_data, gender):\n",
    "    print(f\"\\nTraining model with RFE for {gender}...\\n\")\n",
    "    \n",
    "    X = gender_data.drop(columns=['Segment', 'Subject NO.', 'Gender'])\n",
    "    y_binary = gender_data['Segment'].apply(lambda x: 0 if x == 'EO' else 1)\n",
    "\n",
    "    # Feature Scaling for RFE\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Apply Recursive Feature Elimination (RFE)\n",
    "    logistic_model = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "    rfe = RFE(logistic_model, n_features_to_select=15)  # Adjust the number of features\n",
    "    rfe = rfe.fit(X_scaled, y_binary)\n",
    "\n",
    "    # Select the features chosen by RFE\n",
    "    X_rfe_selected = X_scaled[:, rfe.support_]\n",
    "\n",
    "    X_train_rfe, X_test_rfe, y_train, y_test = train_test_split(X_rfe_selected, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Reshape the selected data for LSTM input [samples, timesteps, features]\n",
    "    X_train_lstm_rfe = X_train_rfe.reshape((X_train_rfe.shape[0], 1, X_train_rfe.shape[1]))\n",
    "    X_test_lstm_rfe = X_test_rfe.reshape((X_test_rfe.shape[0], 1, X_test_rfe.shape[1]))\n",
    "\n",
    "    # Build an improved Hybrid LSTM + NN Model using the selected features\n",
    "    model = Sequential()\n",
    "\n",
    "    # Bidirectional LSTM Layer with max_norm constraint to prevent exploding gradients\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_constraint=max_norm(3)), input_shape=(X_train_lstm_rfe.shape[1], X_train_lstm_rfe.shape[2])))\n",
    "    model.add(Dropout(0.5))  # Increased Dropout rate to reduce overfitting\n",
    "\n",
    "    # Second LSTM Layer for added depth\n",
    "    model.add(LSTM(64, return_sequences=False, kernel_constraint=max_norm(3)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Fully Connected (Dense) Layers with L2 regularization and Dropout\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Output Layer (sigmoid for binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the Model with Adam optimizer and a smaller learning rate\n",
    "    optimizer = Adam(learning_rate=0.0003, clipvalue=1.0)  # Gradient clipping added\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Learning rate scheduler and early stopping\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_lstm_rfe, y_train, epochs=150, batch_size=16, verbose=1, validation_data=(X_test_lstm_rfe, y_test), \n",
    "                callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "    binary_predictions = model.predict(X_test_lstm_rfe)\n",
    "    binary_predictions = (binary_predictions > 0.5).astype(int)\n",
    "\n",
    "    binary_acc = accuracy_score(y_test, binary_predictions)\n",
    "    binary_f1 = f1_score(y_test, binary_predictions)\n",
    "\n",
    "    print(f\"{gender} Model - Accuracy with RFE: {binary_acc}\")\n",
    "    print(f\"{gender} Model - F1 Score with RFE: {binary_f1}\")\n",
    "    \n",
    "    return binary_acc, binary_f1\n",
    "\n",
    "male_data = combined_data[combined_data['Gender'] == 'Male']\n",
    "female_data = combined_data[combined_data['Gender'] == 'Female']\n",
    "\n",
    "male_acc_rfe, male_f1_rfe = build_and_train_rfe_model_by_gender(male_data, 'Male')\n",
    "female_acc_rfe, female_f1_rfe = build_and_train_rfe_model_by_gender(female_data, 'Female')\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results with RFE:\")\n",
    "print(f\"Male Model - Accuracy: {male_acc_rfe}, F1 Score: {male_f1_rfe}\")\n",
    "print(f\"Female Model - Accuracy: {female_acc_rfe}, F1 Score: {female_f1_rfe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EO VS AC1\n",
    "# EO VS AC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 535ms/step - accuracy: 0.5721 - loss: 0.8640 - val_accuracy: 0.4167 - val_loss: 0.8612 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5721 - loss: 0.8589 - val_accuracy: 0.5000 - val_loss: 0.8602 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4744 - loss: 0.8607 - val_accuracy: 0.5000 - val_loss: 0.8592 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.8595 - val_accuracy: 0.5000 - val_loss: 0.8582 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6907 - loss: 0.8539 - val_accuracy: 0.5000 - val_loss: 0.8572 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6442 - loss: 0.8562 - val_accuracy: 0.5000 - val_loss: 0.8562 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5256 - loss: 0.8541 - val_accuracy: 0.5000 - val_loss: 0.8551 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4535 - loss: 0.8515 - val_accuracy: 0.5000 - val_loss: 0.8542 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4792 - loss: 0.8524 - val_accuracy: 0.5000 - val_loss: 0.8532 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6907 - loss: 0.8483 - val_accuracy: 0.5000 - val_loss: 0.8523 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6907 - loss: 0.8476 - val_accuracy: 0.5000 - val_loss: 0.8513 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5929 - loss: 0.8486 - val_accuracy: 0.5000 - val_loss: 0.8504 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6346 - loss: 0.8453 - val_accuracy: 0.5000 - val_loss: 0.8494 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4022 - loss: 0.8483 - val_accuracy: 0.5000 - val_loss: 0.8485 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7837 - loss: 0.8402 - val_accuracy: 0.5000 - val_loss: 0.8475 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7163 - loss: 0.8401 - val_accuracy: 0.5000 - val_loss: 0.8466 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7532 - loss: 0.8368 - val_accuracy: 0.5000 - val_loss: 0.8457 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5256 - loss: 0.8454 - val_accuracy: 0.5000 - val_loss: 0.8447 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6234 - loss: 0.8378 - val_accuracy: 0.5833 - val_loss: 0.8438 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7837 - loss: 0.8344 - val_accuracy: 0.5833 - val_loss: 0.8429 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7885 - loss: 0.8319 - val_accuracy: 0.5833 - val_loss: 0.8420 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7837 - loss: 0.8356 - val_accuracy: 0.5833 - val_loss: 0.8412 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6490 - loss: 0.8333 - val_accuracy: 0.5833 - val_loss: 0.8404 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6955 - loss: 0.8305 - val_accuracy: 0.5833 - val_loss: 0.8396 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8045 - loss: 0.8272 - val_accuracy: 0.5833 - val_loss: 0.8388 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6442 - loss: 0.8336 - val_accuracy: 0.5833 - val_loss: 0.8380 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7115 - loss: 0.8246 - val_accuracy: 0.5833 - val_loss: 0.8372 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7420 - loss: 0.8235 - val_accuracy: 0.5833 - val_loss: 0.8364 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7372 - loss: 0.8225 - val_accuracy: 0.5833 - val_loss: 0.8356 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8558 - loss: 0.8219 - val_accuracy: 0.5833 - val_loss: 0.8348 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6651 - loss: 0.8223 - val_accuracy: 0.5833 - val_loss: 0.8340 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9022 - loss: 0.8200 - val_accuracy: 0.5833 - val_loss: 0.8332 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8558 - loss: 0.8145 - val_accuracy: 0.5833 - val_loss: 0.8324 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6699 - loss: 0.8215 - val_accuracy: 0.5833 - val_loss: 0.8317 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7837 - loss: 0.8135 - val_accuracy: 0.5833 - val_loss: 0.8310 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6907 - loss: 0.8187 - val_accuracy: 0.5833 - val_loss: 0.8302 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8814 - loss: 0.8056 - val_accuracy: 0.5833 - val_loss: 0.8296 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7420 - loss: 0.8180 - val_accuracy: 0.5833 - val_loss: 0.8289 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7115 - loss: 0.8039 - val_accuracy: 0.5833 - val_loss: 0.8282 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8558 - loss: 0.8063 - val_accuracy: 0.5833 - val_loss: 0.8276 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7837 - loss: 0.8000 - val_accuracy: 0.5833 - val_loss: 0.8271 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7163 - loss: 0.7977 - val_accuracy: 0.5833 - val_loss: 0.8266 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8510 - loss: 0.7974 - val_accuracy: 0.5833 - val_loss: 0.8260 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6907 - loss: 0.7891 - val_accuracy: 0.5833 - val_loss: 0.8253 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7837 - loss: 0.7897 - val_accuracy: 0.5833 - val_loss: 0.8247 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7115 - loss: 0.7920 - val_accuracy: 0.5000 - val_loss: 0.8242 - learning_rate: 3.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6907 - loss: 0.7967 - val_accuracy: 0.5000 - val_loss: 0.8236 - learning_rate: 3.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8974 - loss: 0.7755 - val_accuracy: 0.5000 - val_loss: 0.8230 - learning_rate: 3.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7837 - loss: 0.7845 - val_accuracy: 0.5000 - val_loss: 0.8222 - learning_rate: 3.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8301 - loss: 0.7813 - val_accuracy: 0.5000 - val_loss: 0.8214 - learning_rate: 3.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8045 - loss: 0.7597 - val_accuracy: 0.5000 - val_loss: 0.8207 - learning_rate: 3.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8558 - loss: 0.7681 - val_accuracy: 0.5000 - val_loss: 0.8202 - learning_rate: 3.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8141 - loss: 0.7651 - val_accuracy: 0.5000 - val_loss: 0.8194 - learning_rate: 3.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7885 - loss: 0.7616 - val_accuracy: 0.5000 - val_loss: 0.8187 - learning_rate: 3.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8558 - loss: 0.7568 - val_accuracy: 0.5000 - val_loss: 0.8182 - learning_rate: 3.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8558 - loss: 0.7470 - val_accuracy: 0.5000 - val_loss: 0.8177 - learning_rate: 3.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8349 - loss: 0.7545 - val_accuracy: 0.5000 - val_loss: 0.8172 - learning_rate: 3.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7885 - loss: 0.7426 - val_accuracy: 0.5000 - val_loss: 0.8167 - learning_rate: 3.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9071 - loss: 0.7385 - val_accuracy: 0.5000 - val_loss: 0.8162 - learning_rate: 3.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8814 - loss: 0.7302 - val_accuracy: 0.5000 - val_loss: 0.8157 - learning_rate: 3.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8766 - loss: 0.7257 - val_accuracy: 0.5000 - val_loss: 0.8151 - learning_rate: 3.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8558 - loss: 0.7203 - val_accuracy: 0.5000 - val_loss: 0.8145 - learning_rate: 3.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8558 - loss: 0.7166 - val_accuracy: 0.5000 - val_loss: 0.8137 - learning_rate: 3.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8606 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.8128 - learning_rate: 3.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8606 - loss: 0.7100 - val_accuracy: 0.5000 - val_loss: 0.8120 - learning_rate: 3.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8349 - loss: 0.6820 - val_accuracy: 0.5000 - val_loss: 0.8113 - learning_rate: 3.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8558 - loss: 0.6748 - val_accuracy: 0.5000 - val_loss: 0.8108 - learning_rate: 3.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9279 - loss: 0.6517 - val_accuracy: 0.5000 - val_loss: 0.8104 - learning_rate: 3.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8141 - loss: 0.6654 - val_accuracy: 0.5000 - val_loss: 0.8101 - learning_rate: 3.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9071 - loss: 0.6516 - val_accuracy: 0.5000 - val_loss: 0.8107 - learning_rate: 3.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8814 - loss: 0.6274 - val_accuracy: 0.5000 - val_loss: 0.8108 - learning_rate: 3.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.6462 - val_accuracy: 0.5833 - val_loss: 0.8111 - learning_rate: 3.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8606 - loss: 0.6002 - val_accuracy: 0.5833 - val_loss: 0.8120 - learning_rate: 3.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9022 - loss: 0.5990 - val_accuracy: 0.5833 - val_loss: 0.8132 - learning_rate: 3.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8814 - loss: 0.5946 - val_accuracy: 0.5833 - val_loss: 0.8138 - learning_rate: 1.5000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9487 - loss: 0.5755 - val_accuracy: 0.5833 - val_loss: 0.8146 - learning_rate: 1.5000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8814 - loss: 0.5690 - val_accuracy: 0.5833 - val_loss: 0.8153 - learning_rate: 1.5000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8814 - loss: 0.5927 - val_accuracy: 0.5833 - val_loss: 0.8158 - learning_rate: 1.5000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9022 - loss: 0.5537 - val_accuracy: 0.5833 - val_loss: 0.8167 - learning_rate: 1.5000e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step\n",
      "Male - EO vs AC1 Accuracy: 0.5, F1 Score: 0.4\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 515ms/step - accuracy: 0.2163 - loss: 0.8705 - val_accuracy: 0.5833 - val_loss: 0.8630 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4792 - loss: 0.8642 - val_accuracy: 0.5833 - val_loss: 0.8617 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4535 - loss: 0.8616 - val_accuracy: 0.5000 - val_loss: 0.8603 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6394 - loss: 0.8601 - val_accuracy: 0.5000 - val_loss: 0.8590 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4119 - loss: 0.8615 - val_accuracy: 0.5833 - val_loss: 0.8577 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3558 - loss: 0.8629 - val_accuracy: 0.6667 - val_loss: 0.8564 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5721 - loss: 0.8576 - val_accuracy: 0.7500 - val_loss: 0.8551 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6651 - loss: 0.8509 - val_accuracy: 0.6667 - val_loss: 0.8538 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6603 - loss: 0.8543 - val_accuracy: 0.6667 - val_loss: 0.8525 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6442 - loss: 0.8502 - val_accuracy: 0.6667 - val_loss: 0.8512 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6186 - loss: 0.8514 - val_accuracy: 0.6667 - val_loss: 0.8499 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5465 - loss: 0.8494 - val_accuracy: 0.6667 - val_loss: 0.8486 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8045 - loss: 0.8451 - val_accuracy: 0.7500 - val_loss: 0.8473 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7276 - loss: 0.8458 - val_accuracy: 0.7500 - val_loss: 0.8459 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7420 - loss: 0.8442 - val_accuracy: 0.7500 - val_loss: 0.8445 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4792 - loss: 0.8520 - val_accuracy: 0.7500 - val_loss: 0.8432 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6442 - loss: 0.8433 - val_accuracy: 0.7500 - val_loss: 0.8418 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6490 - loss: 0.8428 - val_accuracy: 0.7500 - val_loss: 0.8403 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6442 - loss: 0.8393 - val_accuracy: 0.7500 - val_loss: 0.8388 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8349 - loss: 0.8347 - val_accuracy: 0.7500 - val_loss: 0.8373 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6442 - loss: 0.8367 - val_accuracy: 0.7500 - val_loss: 0.8356 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5978 - loss: 0.8403 - val_accuracy: 0.7500 - val_loss: 0.8340 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7580 - loss: 0.8321 - val_accuracy: 0.7500 - val_loss: 0.8324 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8141 - loss: 0.8268 - val_accuracy: 0.7500 - val_loss: 0.8307 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7837 - loss: 0.8198 - val_accuracy: 0.7500 - val_loss: 0.8290 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8349 - loss: 0.8275 - val_accuracy: 0.7500 - val_loss: 0.8272 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6907 - loss: 0.8288 - val_accuracy: 0.7500 - val_loss: 0.8255 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8558 - loss: 0.8269 - val_accuracy: 0.7500 - val_loss: 0.8237 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8558 - loss: 0.8222 - val_accuracy: 0.7500 - val_loss: 0.8218 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8045 - loss: 0.8174 - val_accuracy: 0.7500 - val_loss: 0.8199 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8301 - loss: 0.8143 - val_accuracy: 0.7500 - val_loss: 0.8179 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8814 - loss: 0.8176 - val_accuracy: 0.7500 - val_loss: 0.8159 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8814 - loss: 0.8116 - val_accuracy: 0.7500 - val_loss: 0.8138 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8301 - loss: 0.8101 - val_accuracy: 0.7500 - val_loss: 0.8116 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8766 - loss: 0.8086 - val_accuracy: 0.7500 - val_loss: 0.8093 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8814 - loss: 0.8031 - val_accuracy: 0.7500 - val_loss: 0.8069 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8141 - loss: 0.8021 - val_accuracy: 0.7500 - val_loss: 0.8044 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8349 - loss: 0.7908 - val_accuracy: 0.7500 - val_loss: 0.8017 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7628 - loss: 0.7996 - val_accuracy: 0.7500 - val_loss: 0.7989 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8558 - loss: 0.7965 - val_accuracy: 0.7500 - val_loss: 0.7960 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8558 - loss: 0.7913 - val_accuracy: 0.7500 - val_loss: 0.7931 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8558 - loss: 0.7859 - val_accuracy: 0.7500 - val_loss: 0.7900 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8558 - loss: 0.7800 - val_accuracy: 0.7500 - val_loss: 0.7867 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8814 - loss: 0.7760 - val_accuracy: 0.7500 - val_loss: 0.7834 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8349 - loss: 0.7722 - val_accuracy: 0.7500 - val_loss: 0.7800 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8558 - loss: 0.7640 - val_accuracy: 0.7500 - val_loss: 0.7764 - learning_rate: 3.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9279 - loss: 0.7515 - val_accuracy: 0.7500 - val_loss: 0.7725 - learning_rate: 3.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9279 - loss: 0.7516 - val_accuracy: 0.7500 - val_loss: 0.7684 - learning_rate: 3.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9071 - loss: 0.7444 - val_accuracy: 0.7500 - val_loss: 0.7641 - learning_rate: 3.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8141 - loss: 0.7454 - val_accuracy: 0.7500 - val_loss: 0.7598 - learning_rate: 3.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8814 - loss: 0.7419 - val_accuracy: 0.7500 - val_loss: 0.7552 - learning_rate: 3.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9022 - loss: 0.7364 - val_accuracy: 0.7500 - val_loss: 0.7505 - learning_rate: 3.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9071 - loss: 0.7194 - val_accuracy: 0.7500 - val_loss: 0.7455 - learning_rate: 3.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.7285 - val_accuracy: 0.7500 - val_loss: 0.7404 - learning_rate: 3.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8766 - loss: 0.6910 - val_accuracy: 0.7500 - val_loss: 0.7351 - learning_rate: 3.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.7061 - val_accuracy: 0.7500 - val_loss: 0.7296 - learning_rate: 3.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9022 - loss: 0.6979 - val_accuracy: 0.7500 - val_loss: 0.7242 - learning_rate: 3.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.6923 - val_accuracy: 0.7500 - val_loss: 0.7187 - learning_rate: 3.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8606 - loss: 0.6852 - val_accuracy: 0.7500 - val_loss: 0.7132 - learning_rate: 3.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9279 - loss: 0.6371 - val_accuracy: 0.7500 - val_loss: 0.7074 - learning_rate: 3.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9022 - loss: 0.6543 - val_accuracy: 0.7500 - val_loss: 0.7015 - learning_rate: 3.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8814 - loss: 0.6540 - val_accuracy: 0.7500 - val_loss: 0.6955 - learning_rate: 3.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9022 - loss: 0.6332 - val_accuracy: 0.7500 - val_loss: 0.6894 - learning_rate: 3.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8814 - loss: 0.6211 - val_accuracy: 0.7500 - val_loss: 0.6832 - learning_rate: 3.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.6165 - val_accuracy: 0.7500 - val_loss: 0.6770 - learning_rate: 3.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9279 - loss: 0.6066 - val_accuracy: 0.7500 - val_loss: 0.6708 - learning_rate: 3.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9487 - loss: 0.6046 - val_accuracy: 0.7500 - val_loss: 0.6646 - learning_rate: 3.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8606 - loss: 0.5888 - val_accuracy: 0.7500 - val_loss: 0.6587 - learning_rate: 3.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9231 - loss: 0.5285 - val_accuracy: 0.7500 - val_loss: 0.6530 - learning_rate: 3.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9535 - loss: 0.5652 - val_accuracy: 0.7500 - val_loss: 0.6477 - learning_rate: 3.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.5291 - val_accuracy: 0.7500 - val_loss: 0.6423 - learning_rate: 3.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9279 - loss: 0.5118 - val_accuracy: 0.7500 - val_loss: 0.6375 - learning_rate: 3.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.5026 - val_accuracy: 0.7500 - val_loss: 0.6330 - learning_rate: 3.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8606 - loss: 0.5200 - val_accuracy: 0.7500 - val_loss: 0.6288 - learning_rate: 3.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.5054 - val_accuracy: 0.7500 - val_loss: 0.6250 - learning_rate: 3.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9071 - loss: 0.5064 - val_accuracy: 0.7500 - val_loss: 0.6212 - learning_rate: 3.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9535 - loss: 0.4507 - val_accuracy: 0.7500 - val_loss: 0.6177 - learning_rate: 3.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8814 - loss: 0.5036 - val_accuracy: 0.6667 - val_loss: 0.6150 - learning_rate: 3.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9071 - loss: 0.4549 - val_accuracy: 0.6667 - val_loss: 0.6124 - learning_rate: 3.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9279 - loss: 0.4140 - val_accuracy: 0.6667 - val_loss: 0.6105 - learning_rate: 3.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9535 - loss: 0.4104 - val_accuracy: 0.6667 - val_loss: 0.6087 - learning_rate: 3.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9535 - loss: 0.4370 - val_accuracy: 0.6667 - val_loss: 0.6080 - learning_rate: 3.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9071 - loss: 0.4361 - val_accuracy: 0.6667 - val_loss: 0.6080 - learning_rate: 3.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9535 - loss: 0.4258 - val_accuracy: 0.6667 - val_loss: 0.6083 - learning_rate: 3.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9279 - loss: 0.3855 - val_accuracy: 0.6667 - val_loss: 0.6086 - learning_rate: 3.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9279 - loss: 0.3801 - val_accuracy: 0.6667 - val_loss: 0.6095 - learning_rate: 3.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9071 - loss: 0.4278 - val_accuracy: 0.6667 - val_loss: 0.6123 - learning_rate: 3.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9279 - loss: 0.3811 - val_accuracy: 0.6667 - val_loss: 0.6133 - learning_rate: 1.5000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9744 - loss: 0.3615 - val_accuracy: 0.6667 - val_loss: 0.6137 - learning_rate: 1.5000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9535 - loss: 0.3840 - val_accuracy: 0.6667 - val_loss: 0.6137 - learning_rate: 1.5000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8814 - loss: 0.3399 - val_accuracy: 0.6667 - val_loss: 0.6143 - learning_rate: 1.5000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9071 - loss: 0.3391 - val_accuracy: 0.6667 - val_loss: 0.6155 - learning_rate: 1.5000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9535 - loss: 0.3325 - val_accuracy: 0.6667 - val_loss: 0.6159 - learning_rate: 7.5000e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
      "Male - EO vs AC2 Accuracy: 0.6666666666666666, F1 Score: 0.6\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 519ms/step - accuracy: 0.2672 - loss: 0.8688 - val_accuracy: 0.5385 - val_loss: 0.8616 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4260 - loss: 0.8635 - val_accuracy: 0.5385 - val_loss: 0.8603 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4009 - loss: 0.8600 - val_accuracy: 0.5385 - val_loss: 0.8590 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5136 - loss: 0.8563 - val_accuracy: 0.5385 - val_loss: 0.8577 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5761 - loss: 0.8540 - val_accuracy: 0.5385 - val_loss: 0.8564 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4885 - loss: 0.8569 - val_accuracy: 0.5385 - val_loss: 0.8552 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5323 - loss: 0.8523 - val_accuracy: 0.6923 - val_loss: 0.8538 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5970 - loss: 0.8532 - val_accuracy: 0.7692 - val_loss: 0.8526 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5345 - loss: 0.8520 - val_accuracy: 0.7692 - val_loss: 0.8513 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6200 - loss: 0.8495 - val_accuracy: 0.7692 - val_loss: 0.8501 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5761 - loss: 0.8476 - val_accuracy: 0.7692 - val_loss: 0.8488 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5575 - loss: 0.8463 - val_accuracy: 0.7692 - val_loss: 0.8475 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5323 - loss: 0.8473 - val_accuracy: 0.7692 - val_loss: 0.8462 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6889 - loss: 0.8469 - val_accuracy: 0.7692 - val_loss: 0.8450 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5553 - loss: 0.8444 - val_accuracy: 0.7692 - val_loss: 0.8437 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6451 - loss: 0.8386 - val_accuracy: 0.7692 - val_loss: 0.8423 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6451 - loss: 0.8403 - val_accuracy: 0.7692 - val_loss: 0.8410 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5805 - loss: 0.8426 - val_accuracy: 0.7692 - val_loss: 0.8396 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6200 - loss: 0.8400 - val_accuracy: 0.7692 - val_loss: 0.8383 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4468 - loss: 0.8389 - val_accuracy: 0.7692 - val_loss: 0.8369 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7974 - loss: 0.8316 - val_accuracy: 0.7692 - val_loss: 0.8355 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6659 - loss: 0.8362 - val_accuracy: 0.7692 - val_loss: 0.8341 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6013 - loss: 0.8340 - val_accuracy: 0.7692 - val_loss: 0.8327 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6681 - loss: 0.8270 - val_accuracy: 0.7692 - val_loss: 0.8312 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6221 - loss: 0.8317 - val_accuracy: 0.7692 - val_loss: 0.8297 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6243 - loss: 0.8275 - val_accuracy: 0.6923 - val_loss: 0.8281 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6911 - loss: 0.8251 - val_accuracy: 0.6923 - val_loss: 0.8265 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6681 - loss: 0.8163 - val_accuracy: 0.6923 - val_loss: 0.8248 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6451 - loss: 0.8252 - val_accuracy: 0.6923 - val_loss: 0.8232 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7328 - loss: 0.8137 - val_accuracy: 0.6923 - val_loss: 0.8215 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7557 - loss: 0.8141 - val_accuracy: 0.6923 - val_loss: 0.8197 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7996 - loss: 0.8078 - val_accuracy: 0.6923 - val_loss: 0.8178 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6681 - loss: 0.8140 - val_accuracy: 0.6923 - val_loss: 0.8159 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6200 - loss: 0.8066 - val_accuracy: 0.6923 - val_loss: 0.8139 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7306 - loss: 0.8008 - val_accuracy: 0.6923 - val_loss: 0.8119 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7766 - loss: 0.8026 - val_accuracy: 0.6923 - val_loss: 0.8099 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7328 - loss: 0.8017 - val_accuracy: 0.6923 - val_loss: 0.8077 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8412 - loss: 0.7982 - val_accuracy: 0.6923 - val_loss: 0.8055 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6889 - loss: 0.7983 - val_accuracy: 0.6923 - val_loss: 0.8031 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7328 - loss: 0.7975 - val_accuracy: 0.6923 - val_loss: 0.8007 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7557 - loss: 0.7970 - val_accuracy: 0.6923 - val_loss: 0.7982 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7119 - loss: 0.7871 - val_accuracy: 0.6923 - val_loss: 0.7957 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7557 - loss: 0.7835 - val_accuracy: 0.6923 - val_loss: 0.7931 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6911 - loss: 0.7855 - val_accuracy: 0.6923 - val_loss: 0.7902 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7328 - loss: 0.7820 - val_accuracy: 0.6923 - val_loss: 0.7873 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6659 - loss: 0.7615 - val_accuracy: 0.6923 - val_loss: 0.7844 - learning_rate: 3.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7328 - loss: 0.7663 - val_accuracy: 0.6923 - val_loss: 0.7814 - learning_rate: 3.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7557 - loss: 0.7673 - val_accuracy: 0.6923 - val_loss: 0.7784 - learning_rate: 3.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7996 - loss: 0.7573 - val_accuracy: 0.6923 - val_loss: 0.7752 - learning_rate: 3.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6243 - loss: 0.7657 - val_accuracy: 0.6923 - val_loss: 0.7720 - learning_rate: 3.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6659 - loss: 0.7430 - val_accuracy: 0.6923 - val_loss: 0.7688 - learning_rate: 3.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7766 - loss: 0.7270 - val_accuracy: 0.6923 - val_loss: 0.7654 - learning_rate: 3.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8226 - loss: 0.7338 - val_accuracy: 0.6923 - val_loss: 0.7620 - learning_rate: 3.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7557 - loss: 0.7331 - val_accuracy: 0.6923 - val_loss: 0.7585 - learning_rate: 3.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7536 - loss: 0.7028 - val_accuracy: 0.6923 - val_loss: 0.7548 - learning_rate: 3.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7766 - loss: 0.7159 - val_accuracy: 0.6923 - val_loss: 0.7514 - learning_rate: 3.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7996 - loss: 0.7049 - val_accuracy: 0.6923 - val_loss: 0.7479 - learning_rate: 3.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7996 - loss: 0.7082 - val_accuracy: 0.7692 - val_loss: 0.7445 - learning_rate: 3.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8642 - loss: 0.7149 - val_accuracy: 0.7692 - val_loss: 0.7410 - learning_rate: 3.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8455 - loss: 0.6747 - val_accuracy: 0.7692 - val_loss: 0.7375 - learning_rate: 3.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7557 - loss: 0.6859 - val_accuracy: 0.7692 - val_loss: 0.7337 - learning_rate: 3.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8204 - loss: 0.6765 - val_accuracy: 0.7692 - val_loss: 0.7302 - learning_rate: 3.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7996 - loss: 0.6681 - val_accuracy: 0.7692 - val_loss: 0.7265 - learning_rate: 3.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7996 - loss: 0.6540 - val_accuracy: 0.7692 - val_loss: 0.7229 - learning_rate: 3.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7557 - loss: 0.6646 - val_accuracy: 0.6923 - val_loss: 0.7192 - learning_rate: 3.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7328 - loss: 0.6536 - val_accuracy: 0.6923 - val_loss: 0.7153 - learning_rate: 3.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8434 - loss: 0.6568 - val_accuracy: 0.6923 - val_loss: 0.7114 - learning_rate: 3.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7141 - loss: 0.6795 - val_accuracy: 0.6923 - val_loss: 0.7074 - learning_rate: 3.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7349 - loss: 0.6750 - val_accuracy: 0.6923 - val_loss: 0.7034 - learning_rate: 3.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7996 - loss: 0.6433 - val_accuracy: 0.6923 - val_loss: 0.6992 - learning_rate: 3.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8664 - loss: 0.6331 - val_accuracy: 0.6923 - val_loss: 0.6953 - learning_rate: 3.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7349 - loss: 0.6542 - val_accuracy: 0.6923 - val_loss: 0.6911 - learning_rate: 3.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7996 - loss: 0.6359 - val_accuracy: 0.6923 - val_loss: 0.6869 - learning_rate: 3.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7996 - loss: 0.6236 - val_accuracy: 0.7692 - val_loss: 0.6819 - learning_rate: 3.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8455 - loss: 0.6091 - val_accuracy: 0.7692 - val_loss: 0.6763 - learning_rate: 3.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7579 - loss: 0.5932 - val_accuracy: 0.7692 - val_loss: 0.6704 - learning_rate: 3.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9540 - loss: 0.5948 - val_accuracy: 0.7692 - val_loss: 0.6645 - learning_rate: 3.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9102 - loss: 0.5794 - val_accuracy: 0.8462 - val_loss: 0.6583 - learning_rate: 3.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8872 - loss: 0.5888 - val_accuracy: 0.8462 - val_loss: 0.6519 - learning_rate: 3.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8894 - loss: 0.5753 - val_accuracy: 0.8462 - val_loss: 0.6452 - learning_rate: 3.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8894 - loss: 0.5700 - val_accuracy: 0.8462 - val_loss: 0.6383 - learning_rate: 3.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8664 - loss: 0.5589 - val_accuracy: 0.8462 - val_loss: 0.6311 - learning_rate: 3.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9080 - loss: 0.5430 - val_accuracy: 0.9231 - val_loss: 0.6239 - learning_rate: 3.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9102 - loss: 0.5554 - val_accuracy: 0.9231 - val_loss: 0.6164 - learning_rate: 3.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8685 - loss: 0.5820 - val_accuracy: 0.9231 - val_loss: 0.6093 - learning_rate: 3.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8894 - loss: 0.5489 - val_accuracy: 0.9231 - val_loss: 0.6017 - learning_rate: 3.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9102 - loss: 0.5143 - val_accuracy: 0.9231 - val_loss: 0.5942 - learning_rate: 3.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9102 - loss: 0.5228 - val_accuracy: 0.9231 - val_loss: 0.5869 - learning_rate: 3.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9332 - loss: 0.5075 - val_accuracy: 0.9231 - val_loss: 0.5793 - learning_rate: 3.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8455 - loss: 0.5109 - val_accuracy: 0.9231 - val_loss: 0.5719 - learning_rate: 3.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9332 - loss: 0.4826 - val_accuracy: 0.9231 - val_loss: 0.5643 - learning_rate: 3.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8894 - loss: 0.4919 - val_accuracy: 0.9231 - val_loss: 0.5567 - learning_rate: 3.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9124 - loss: 0.4587 - val_accuracy: 0.9231 - val_loss: 0.5491 - learning_rate: 3.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8894 - loss: 0.4372 - val_accuracy: 0.9231 - val_loss: 0.5411 - learning_rate: 3.0000e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8894 - loss: 0.4763 - val_accuracy: 0.9231 - val_loss: 0.5334 - learning_rate: 3.0000e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8685 - loss: 0.4499 - val_accuracy: 0.9231 - val_loss: 0.5263 - learning_rate: 3.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9102 - loss: 0.4538 - val_accuracy: 0.9231 - val_loss: 0.5193 - learning_rate: 3.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9770 - loss: 0.4162 - val_accuracy: 0.9231 - val_loss: 0.5118 - learning_rate: 3.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8664 - loss: 0.4751 - val_accuracy: 0.9231 - val_loss: 0.5047 - learning_rate: 3.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9332 - loss: 0.4045 - val_accuracy: 0.9231 - val_loss: 0.4973 - learning_rate: 3.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9102 - loss: 0.4240 - val_accuracy: 0.9231 - val_loss: 0.4901 - learning_rate: 3.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9770 - loss: 0.3804 - val_accuracy: 0.9231 - val_loss: 0.4825 - learning_rate: 3.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9332 - loss: 0.4100 - val_accuracy: 0.9231 - val_loss: 0.4754 - learning_rate: 3.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9562 - loss: 0.3851 - val_accuracy: 0.9231 - val_loss: 0.4683 - learning_rate: 3.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9770 - loss: 0.3929 - val_accuracy: 0.9231 - val_loss: 0.4619 - learning_rate: 3.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9770 - loss: 0.3500 - val_accuracy: 0.9231 - val_loss: 0.4560 - learning_rate: 3.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9562 - loss: 0.3674 - val_accuracy: 0.9231 - val_loss: 0.4502 - learning_rate: 3.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9562 - loss: 0.3581 - val_accuracy: 0.9231 - val_loss: 0.4441 - learning_rate: 3.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9332 - loss: 0.3360 - val_accuracy: 0.9231 - val_loss: 0.4390 - learning_rate: 3.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9562 - loss: 0.3450 - val_accuracy: 0.9231 - val_loss: 0.4338 - learning_rate: 3.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.3330 - val_accuracy: 0.9231 - val_loss: 0.4289 - learning_rate: 3.0000e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.3111 - val_accuracy: 0.9231 - val_loss: 0.4249 - learning_rate: 3.0000e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9124 - loss: 0.3123 - val_accuracy: 0.9231 - val_loss: 0.4209 - learning_rate: 3.0000e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2868 - val_accuracy: 0.9231 - val_loss: 0.4173 - learning_rate: 3.0000e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8894 - loss: 0.3555 - val_accuracy: 0.9231 - val_loss: 0.4123 - learning_rate: 3.0000e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9562 - loss: 0.2990 - val_accuracy: 0.9231 - val_loss: 0.4071 - learning_rate: 3.0000e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9540 - loss: 0.2909 - val_accuracy: 0.9231 - val_loss: 0.4024 - learning_rate: 3.0000e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9124 - loss: 0.3010 - val_accuracy: 0.9231 - val_loss: 0.3972 - learning_rate: 3.0000e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9102 - loss: 0.3016 - val_accuracy: 0.9231 - val_loss: 0.3927 - learning_rate: 3.0000e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2601 - val_accuracy: 0.9231 - val_loss: 0.3898 - learning_rate: 3.0000e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2756 - val_accuracy: 0.9231 - val_loss: 0.3879 - learning_rate: 3.0000e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.2760 - val_accuracy: 0.9231 - val_loss: 0.3880 - learning_rate: 3.0000e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2446 - val_accuracy: 0.9231 - val_loss: 0.3877 - learning_rate: 3.0000e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.2552 - val_accuracy: 0.9231 - val_loss: 0.3882 - learning_rate: 3.0000e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.2334 - val_accuracy: 0.9231 - val_loss: 0.3885 - learning_rate: 3.0000e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9770 - loss: 0.2090 - val_accuracy: 0.9231 - val_loss: 0.3897 - learning_rate: 3.0000e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9770 - loss: 0.2462 - val_accuracy: 0.9231 - val_loss: 0.3901 - learning_rate: 3.0000e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9770 - loss: 0.2313 - val_accuracy: 0.9231 - val_loss: 0.3885 - learning_rate: 3.0000e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2140 - val_accuracy: 0.9231 - val_loss: 0.3878 - learning_rate: 1.5000e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9562 - loss: 0.2367 - val_accuracy: 0.9231 - val_loss: 0.3880 - learning_rate: 1.5000e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2573 - val_accuracy: 0.9231 - val_loss: 0.3876 - learning_rate: 1.5000e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.2338 - val_accuracy: 0.9231 - val_loss: 0.3866 - learning_rate: 1.5000e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.2424 - val_accuracy: 0.9231 - val_loss: 0.3860 - learning_rate: 1.5000e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9770 - loss: 0.2306 - val_accuracy: 0.9231 - val_loss: 0.3856 - learning_rate: 1.5000e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.2056 - val_accuracy: 0.9231 - val_loss: 0.3854 - learning_rate: 1.5000e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.2094 - val_accuracy: 0.9231 - val_loss: 0.3850 - learning_rate: 1.5000e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.2415 - val_accuracy: 0.9231 - val_loss: 0.3847 - learning_rate: 1.5000e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.2096 - val_accuracy: 0.9231 - val_loss: 0.3842 - learning_rate: 1.5000e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2144 - val_accuracy: 0.9231 - val_loss: 0.3836 - learning_rate: 1.5000e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1889 - val_accuracy: 0.9231 - val_loss: 0.3833 - learning_rate: 1.5000e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.1930 - val_accuracy: 0.9231 - val_loss: 0.3835 - learning_rate: 1.5000e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9332 - loss: 0.2428 - val_accuracy: 0.9231 - val_loss: 0.3845 - learning_rate: 1.5000e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1836 - val_accuracy: 0.9231 - val_loss: 0.3852 - learning_rate: 1.5000e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.1852 - val_accuracy: 0.9231 - val_loss: 0.3861 - learning_rate: 1.5000e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2072 - val_accuracy: 0.9231 - val_loss: 0.3870 - learning_rate: 1.5000e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1904 - val_accuracy: 0.9231 - val_loss: 0.3875 - learning_rate: 7.5000e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.2073 - val_accuracy: 0.9231 - val_loss: 0.3880 - learning_rate: 7.5000e-05\n",
      "Epoch 148/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.1703 - val_accuracy: 0.9231 - val_loss: 0.3882 - learning_rate: 7.5000e-05\n",
      "Epoch 149/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.1963 - val_accuracy: 0.9231 - val_loss: 0.3885 - learning_rate: 7.5000e-05\n",
      "Epoch 150/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.2200 - val_accuracy: 0.9231 - val_loss: 0.3884 - learning_rate: 7.5000e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step\n",
      "Female - EO vs AC1 Accuracy: 0.9230769230769231, F1 Score: 0.9090909090909091\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0king\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 505ms/step - accuracy: 0.4864 - loss: 0.8630 - val_accuracy: 0.4615 - val_loss: 0.8627 - learning_rate: 3.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4907 - loss: 0.8617 - val_accuracy: 0.4615 - val_loss: 0.8611 - learning_rate: 3.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5115 - loss: 0.8632 - val_accuracy: 0.4615 - val_loss: 0.8595 - learning_rate: 3.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5136 - loss: 0.8585 - val_accuracy: 0.4615 - val_loss: 0.8580 - learning_rate: 3.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6200 - loss: 0.8567 - val_accuracy: 0.4615 - val_loss: 0.8565 - learning_rate: 3.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4885 - loss: 0.8603 - val_accuracy: 0.4615 - val_loss: 0.8550 - learning_rate: 3.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7328 - loss: 0.8555 - val_accuracy: 0.4615 - val_loss: 0.8535 - learning_rate: 3.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6681 - loss: 0.8539 - val_accuracy: 0.4615 - val_loss: 0.8520 - learning_rate: 3.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6868 - loss: 0.8532 - val_accuracy: 0.5385 - val_loss: 0.8505 - learning_rate: 3.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5991 - loss: 0.8478 - val_accuracy: 0.6154 - val_loss: 0.8490 - learning_rate: 3.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6616 - loss: 0.8470 - val_accuracy: 0.6923 - val_loss: 0.8474 - learning_rate: 3.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6451 - loss: 0.8481 - val_accuracy: 0.7692 - val_loss: 0.8458 - learning_rate: 3.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5805 - loss: 0.8468 - val_accuracy: 0.7692 - val_loss: 0.8442 - learning_rate: 3.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5366 - loss: 0.8475 - val_accuracy: 0.7692 - val_loss: 0.8426 - learning_rate: 3.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7098 - loss: 0.8393 - val_accuracy: 0.7692 - val_loss: 0.8409 - learning_rate: 3.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5345 - loss: 0.8444 - val_accuracy: 0.7692 - val_loss: 0.8393 - learning_rate: 3.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6013 - loss: 0.8430 - val_accuracy: 0.7692 - val_loss: 0.8376 - learning_rate: 3.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6659 - loss: 0.8395 - val_accuracy: 0.7692 - val_loss: 0.8358 - learning_rate: 3.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6221 - loss: 0.8387 - val_accuracy: 0.8462 - val_loss: 0.8340 - learning_rate: 3.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7536 - loss: 0.8324 - val_accuracy: 0.8462 - val_loss: 0.8322 - learning_rate: 3.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7766 - loss: 0.8298 - val_accuracy: 0.8462 - val_loss: 0.8302 - learning_rate: 3.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7119 - loss: 0.8339 - val_accuracy: 0.8462 - val_loss: 0.8282 - learning_rate: 3.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7098 - loss: 0.8321 - val_accuracy: 0.8462 - val_loss: 0.8262 - learning_rate: 3.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7766 - loss: 0.8249 - val_accuracy: 0.8462 - val_loss: 0.8240 - learning_rate: 3.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7098 - loss: 0.8223 - val_accuracy: 0.8462 - val_loss: 0.8218 - learning_rate: 3.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7328 - loss: 0.8245 - val_accuracy: 0.9231 - val_loss: 0.8195 - learning_rate: 3.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8226 - loss: 0.8248 - val_accuracy: 0.9231 - val_loss: 0.8171 - learning_rate: 3.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6681 - loss: 0.8206 - val_accuracy: 0.9231 - val_loss: 0.8146 - learning_rate: 3.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6264 - loss: 0.8219 - val_accuracy: 0.9231 - val_loss: 0.8121 - learning_rate: 3.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6451 - loss: 0.8179 - val_accuracy: 0.9231 - val_loss: 0.8094 - learning_rate: 3.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6911 - loss: 0.8234 - val_accuracy: 0.9231 - val_loss: 0.8068 - learning_rate: 3.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7787 - loss: 0.8125 - val_accuracy: 0.9231 - val_loss: 0.8039 - learning_rate: 3.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7766 - loss: 0.8098 - val_accuracy: 0.9231 - val_loss: 0.8008 - learning_rate: 3.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7996 - loss: 0.8064 - val_accuracy: 0.9231 - val_loss: 0.7977 - learning_rate: 3.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7744 - loss: 0.8006 - val_accuracy: 0.9231 - val_loss: 0.7943 - learning_rate: 3.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7766 - loss: 0.7924 - val_accuracy: 0.9231 - val_loss: 0.7908 - learning_rate: 3.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8642 - loss: 0.7991 - val_accuracy: 0.9231 - val_loss: 0.7870 - learning_rate: 3.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8017 - loss: 0.7943 - val_accuracy: 1.0000 - val_loss: 0.7831 - learning_rate: 3.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8226 - loss: 0.7883 - val_accuracy: 1.0000 - val_loss: 0.7791 - learning_rate: 3.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8017 - loss: 0.7825 - val_accuracy: 1.0000 - val_loss: 0.7748 - learning_rate: 3.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7974 - loss: 0.7870 - val_accuracy: 1.0000 - val_loss: 0.7704 - learning_rate: 3.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8455 - loss: 0.7815 - val_accuracy: 1.0000 - val_loss: 0.7659 - learning_rate: 3.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7996 - loss: 0.7843 - val_accuracy: 1.0000 - val_loss: 0.7613 - learning_rate: 3.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8851 - loss: 0.7546 - val_accuracy: 1.0000 - val_loss: 0.7564 - learning_rate: 3.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7787 - loss: 0.7715 - val_accuracy: 1.0000 - val_loss: 0.7513 - learning_rate: 3.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8226 - loss: 0.7594 - val_accuracy: 1.0000 - val_loss: 0.7459 - learning_rate: 3.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8017 - loss: 0.7639 - val_accuracy: 1.0000 - val_loss: 0.7403 - learning_rate: 3.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8434 - loss: 0.7418 - val_accuracy: 1.0000 - val_loss: 0.7342 - learning_rate: 3.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8455 - loss: 0.7434 - val_accuracy: 1.0000 - val_loss: 0.7277 - learning_rate: 3.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8412 - loss: 0.7443 - val_accuracy: 1.0000 - val_loss: 0.7210 - learning_rate: 3.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8226 - loss: 0.7319 - val_accuracy: 1.0000 - val_loss: 0.7142 - learning_rate: 3.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8894 - loss: 0.7283 - val_accuracy: 1.0000 - val_loss: 0.7071 - learning_rate: 3.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8664 - loss: 0.7094 - val_accuracy: 1.0000 - val_loss: 0.6997 - learning_rate: 3.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8226 - loss: 0.7221 - val_accuracy: 1.0000 - val_loss: 0.6920 - learning_rate: 3.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8226 - loss: 0.7071 - val_accuracy: 1.0000 - val_loss: 0.6839 - learning_rate: 3.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8664 - loss: 0.6925 - val_accuracy: 1.0000 - val_loss: 0.6754 - learning_rate: 3.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8894 - loss: 0.7037 - val_accuracy: 1.0000 - val_loss: 0.6666 - learning_rate: 3.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8894 - loss: 0.6866 - val_accuracy: 1.0000 - val_loss: 0.6576 - learning_rate: 3.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9124 - loss: 0.6740 - val_accuracy: 1.0000 - val_loss: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9332 - loss: 0.6550 - val_accuracy: 1.0000 - val_loss: 0.6383 - learning_rate: 3.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8894 - loss: 0.6426 - val_accuracy: 1.0000 - val_loss: 0.6282 - learning_rate: 3.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9562 - loss: 0.6114 - val_accuracy: 1.0000 - val_loss: 0.6175 - learning_rate: 3.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9332 - loss: 0.6092 - val_accuracy: 1.0000 - val_loss: 0.6061 - learning_rate: 3.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9332 - loss: 0.6265 - val_accuracy: 1.0000 - val_loss: 0.5944 - learning_rate: 3.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9124 - loss: 0.6189 - val_accuracy: 1.0000 - val_loss: 0.5824 - learning_rate: 3.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9124 - loss: 0.5873 - val_accuracy: 1.0000 - val_loss: 0.5699 - learning_rate: 3.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9540 - loss: 0.5617 - val_accuracy: 1.0000 - val_loss: 0.5571 - learning_rate: 3.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8685 - loss: 0.5910 - val_accuracy: 1.0000 - val_loss: 0.5448 - learning_rate: 3.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9124 - loss: 0.5496 - val_accuracy: 1.0000 - val_loss: 0.5325 - learning_rate: 3.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9562 - loss: 0.5299 - val_accuracy: 1.0000 - val_loss: 0.5200 - learning_rate: 3.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9124 - loss: 0.5211 - val_accuracy: 1.0000 - val_loss: 0.5076 - learning_rate: 3.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9562 - loss: 0.4834 - val_accuracy: 1.0000 - val_loss: 0.4950 - learning_rate: 3.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9124 - loss: 0.5103 - val_accuracy: 1.0000 - val_loss: 0.4839 - learning_rate: 3.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9124 - loss: 0.4762 - val_accuracy: 1.0000 - val_loss: 0.4728 - learning_rate: 3.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9124 - loss: 0.4484 - val_accuracy: 1.0000 - val_loss: 0.4618 - learning_rate: 3.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9770 - loss: 0.4704 - val_accuracy: 1.0000 - val_loss: 0.4496 - learning_rate: 3.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.4119 - val_accuracy: 1.0000 - val_loss: 0.4380 - learning_rate: 3.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9332 - loss: 0.4164 - val_accuracy: 1.0000 - val_loss: 0.4263 - learning_rate: 3.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9332 - loss: 0.3881 - val_accuracy: 1.0000 - val_loss: 0.4161 - learning_rate: 3.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.3684 - val_accuracy: 1.0000 - val_loss: 0.4054 - learning_rate: 3.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9332 - loss: 0.3909 - val_accuracy: 1.0000 - val_loss: 0.3961 - learning_rate: 3.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9562 - loss: 0.3633 - val_accuracy: 1.0000 - val_loss: 0.3873 - learning_rate: 3.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9770 - loss: 0.3644 - val_accuracy: 1.0000 - val_loss: 0.3792 - learning_rate: 3.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9770 - loss: 0.3412 - val_accuracy: 1.0000 - val_loss: 0.3716 - learning_rate: 3.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9332 - loss: 0.3649 - val_accuracy: 1.0000 - val_loss: 0.3644 - learning_rate: 3.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9562 - loss: 0.3866 - val_accuracy: 1.0000 - val_loss: 0.3569 - learning_rate: 3.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.3306 - val_accuracy: 1.0000 - val_loss: 0.3498 - learning_rate: 3.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.3045 - val_accuracy: 1.0000 - val_loss: 0.3406 - learning_rate: 3.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.3125 - val_accuracy: 1.0000 - val_loss: 0.3312 - learning_rate: 3.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9562 - loss: 0.3037 - val_accuracy: 1.0000 - val_loss: 0.3224 - learning_rate: 3.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.2699 - val_accuracy: 1.0000 - val_loss: 0.3133 - learning_rate: 3.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.3020 - val_accuracy: 1.0000 - val_loss: 0.3046 - learning_rate: 3.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2591 - val_accuracy: 1.0000 - val_loss: 0.2958 - learning_rate: 3.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.2756 - val_accuracy: 1.0000 - val_loss: 0.2867 - learning_rate: 3.0000e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2717 - val_accuracy: 1.0000 - val_loss: 0.2796 - learning_rate: 3.0000e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.2503 - val_accuracy: 1.0000 - val_loss: 0.2724 - learning_rate: 3.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.2569 - val_accuracy: 1.0000 - val_loss: 0.2653 - learning_rate: 3.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.2353 - val_accuracy: 1.0000 - val_loss: 0.2594 - learning_rate: 3.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9562 - loss: 0.2467 - val_accuracy: 1.0000 - val_loss: 0.2554 - learning_rate: 3.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2209 - val_accuracy: 1.0000 - val_loss: 0.2523 - learning_rate: 3.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.2190 - val_accuracy: 1.0000 - val_loss: 0.2505 - learning_rate: 3.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.2276 - val_accuracy: 1.0000 - val_loss: 0.2493 - learning_rate: 3.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.2374 - val_accuracy: 1.0000 - val_loss: 0.2484 - learning_rate: 3.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9770 - loss: 0.2305 - val_accuracy: 1.0000 - val_loss: 0.2455 - learning_rate: 3.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.2169 - val_accuracy: 1.0000 - val_loss: 0.2404 - learning_rate: 3.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1924 - val_accuracy: 1.0000 - val_loss: 0.2340 - learning_rate: 3.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.2004 - val_accuracy: 1.0000 - val_loss: 0.2282 - learning_rate: 3.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.2039 - val_accuracy: 1.0000 - val_loss: 0.2242 - learning_rate: 3.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.2014 - val_accuracy: 1.0000 - val_loss: 0.2206 - learning_rate: 3.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1846 - val_accuracy: 1.0000 - val_loss: 0.2174 - learning_rate: 3.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1890 - val_accuracy: 1.0000 - val_loss: 0.2137 - learning_rate: 3.0000e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1784 - val_accuracy: 1.0000 - val_loss: 0.2110 - learning_rate: 3.0000e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1909 - val_accuracy: 1.0000 - val_loss: 0.2090 - learning_rate: 3.0000e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1840 - val_accuracy: 1.0000 - val_loss: 0.2070 - learning_rate: 3.0000e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1950 - val_accuracy: 1.0000 - val_loss: 0.2052 - learning_rate: 3.0000e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1773 - val_accuracy: 1.0000 - val_loss: 0.2032 - learning_rate: 3.0000e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1685 - val_accuracy: 1.0000 - val_loss: 0.2013 - learning_rate: 3.0000e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1766 - val_accuracy: 1.0000 - val_loss: 0.1998 - learning_rate: 3.0000e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.1758 - val_accuracy: 1.0000 - val_loss: 0.1983 - learning_rate: 3.0000e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1711 - val_accuracy: 1.0000 - val_loss: 0.1972 - learning_rate: 3.0000e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1806 - val_accuracy: 1.0000 - val_loss: 0.1959 - learning_rate: 3.0000e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1825 - val_accuracy: 1.0000 - val_loss: 0.1935 - learning_rate: 3.0000e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1737 - val_accuracy: 1.0000 - val_loss: 0.1920 - learning_rate: 3.0000e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1626 - val_accuracy: 1.0000 - val_loss: 0.1902 - learning_rate: 3.0000e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1583 - val_accuracy: 1.0000 - val_loss: 0.1873 - learning_rate: 3.0000e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1647 - val_accuracy: 1.0000 - val_loss: 0.1847 - learning_rate: 3.0000e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1491 - val_accuracy: 1.0000 - val_loss: 0.1823 - learning_rate: 3.0000e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1484 - val_accuracy: 1.0000 - val_loss: 0.1807 - learning_rate: 3.0000e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1384 - val_accuracy: 1.0000 - val_loss: 0.1795 - learning_rate: 3.0000e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1418 - val_accuracy: 1.0000 - val_loss: 0.1786 - learning_rate: 3.0000e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9562 - loss: 0.1678 - val_accuracy: 1.0000 - val_loss: 0.1771 - learning_rate: 3.0000e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1523 - val_accuracy: 1.0000 - val_loss: 0.1757 - learning_rate: 3.0000e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1432 - val_accuracy: 1.0000 - val_loss: 0.1744 - learning_rate: 3.0000e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1357 - val_accuracy: 1.0000 - val_loss: 0.1733 - learning_rate: 3.0000e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1381 - val_accuracy: 1.0000 - val_loss: 0.1723 - learning_rate: 3.0000e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1528 - val_accuracy: 1.0000 - val_loss: 0.1715 - learning_rate: 3.0000e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1443 - val_accuracy: 1.0000 - val_loss: 0.1704 - learning_rate: 3.0000e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1332 - val_accuracy: 1.0000 - val_loss: 0.1694 - learning_rate: 3.0000e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1463 - val_accuracy: 1.0000 - val_loss: 0.1684 - learning_rate: 3.0000e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1444 - val_accuracy: 1.0000 - val_loss: 0.1676 - learning_rate: 3.0000e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1362 - val_accuracy: 1.0000 - val_loss: 0.1670 - learning_rate: 3.0000e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1500 - val_accuracy: 1.0000 - val_loss: 0.1666 - learning_rate: 3.0000e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1400 - val_accuracy: 1.0000 - val_loss: 0.1657 - learning_rate: 3.0000e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1323 - val_accuracy: 1.0000 - val_loss: 0.1646 - learning_rate: 3.0000e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1376 - val_accuracy: 1.0000 - val_loss: 0.1636 - learning_rate: 3.0000e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1364 - val_accuracy: 1.0000 - val_loss: 0.1627 - learning_rate: 3.0000e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1356 - val_accuracy: 1.0000 - val_loss: 0.1619 - learning_rate: 3.0000e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1290 - val_accuracy: 1.0000 - val_loss: 0.1612 - learning_rate: 3.0000e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1407 - val_accuracy: 1.0000 - val_loss: 0.1606 - learning_rate: 3.0000e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1345 - val_accuracy: 1.0000 - val_loss: 0.1600 - learning_rate: 3.0000e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\n",
      "Female - EO vs AC2 Accuracy: 1.0, F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "def train_model_by_gender(segment_1, segment_2, gender):\n",
    "    # Filter out data for the two segments and for a specific gender\n",
    "    filtered_data = combined_data[(combined_data['Segment'].isin([segment_1, segment_2])) & (combined_data['Gender'] == gender)]\n",
    "    \n",
    "    # Create binary labels for classification (0 for EO, 1 for AC1 or AC2)\n",
    "    y_binary = filtered_data['Segment'].apply(lambda x: 0 if x == segment_1 else 1)\n",
    "    \n",
    "    X = filtered_data.drop(columns=['Segment', 'Subject NO.', 'Gender'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Apply Recursive Feature Elimination (RFE)\n",
    "    logistic_model = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "    rfe = RFE(logistic_model, n_features_to_select=15)  # Adjust the number of features\n",
    "    rfe = rfe.fit(X_scaled, y_binary)\n",
    "    \n",
    "    # Select the features chosen by RFE\n",
    "    X_rfe_selected = X_scaled[:, rfe.support_]\n",
    "    \n",
    "    # Split the data into training and testing sets using the selected features\n",
    "    X_train_rfe, X_test_rfe, y_train, y_test = train_test_split(X_rfe_selected, y_binary, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Reshape the selected data for LSTM input [samples, timesteps, features]\n",
    "    X_train_lstm_rfe = X_train_rfe.reshape((X_train_rfe.shape[0], 1, X_train_rfe.shape[1]))\n",
    "    X_test_lstm_rfe = X_test_rfe.reshape((X_test_rfe.shape[0], 1, X_test_rfe.shape[1]))\n",
    "    \n",
    "    # Build and compile the model (similar to the previous example)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_constraint=max_norm(3)), input_shape=(X_train_lstm_rfe.shape[1], X_train_lstm_rfe.shape[2])))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64, return_sequences=False, kernel_constraint=max_norm(3)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.0003, clipvalue=1.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # Learning rate scheduler and early stopping\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train_lstm_rfe, y_train, epochs=150, batch_size=16, verbose=1, validation_data=(X_test_lstm_rfe, y_test),\n",
    "                callbacks=[reduce_lr, early_stopping])\n",
    "    \n",
    "    binary_predictions = model.predict(X_test_lstm_rfe)\n",
    "    binary_predictions = (binary_predictions > 0.5).astype(int)\n",
    "    \n",
    "    binary_acc = accuracy_score(y_test, binary_predictions)\n",
    "    binary_f1 = f1_score(y_test, binary_predictions)\n",
    "    \n",
    "    print(f\"{gender.capitalize()} - {segment_1} vs {segment_2} Accuracy: {binary_acc}, F1 Score: {binary_f1}\")\n",
    "\n",
    "train_model_by_gender('EO', 'AC1', 'Male')\n",
    "\n",
    "train_model_by_gender('EO', 'AC2', 'Male')\n",
    "\n",
    "train_model_by_gender('EO', 'AC1', 'Female')\n",
    "\n",
    "train_model_by_gender('EO', 'AC2', 'Female')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
